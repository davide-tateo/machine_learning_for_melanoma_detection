{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Exam Machine Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Davide Tateo; 167275\n",
    "\n",
    "Francesca Salute; 167284\n",
    "\n",
    "Nicole Favero; 167340 \n",
    "\n",
    "Tomás Gonçalves; 167288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required API and modules\n",
    "import warnings\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_to_df(base_path):\n",
    "    data = {'photo_id': [], 'image': [], 'image_array' :[], 'malignant': []}\n",
    "    categories = {'Benign': 0, 'Malignant': 1}\n",
    "    \n",
    "    for subset in ['train', 'test']:\n",
    "        for category in ['Benign', 'Malignant']:\n",
    "            folder_path = os.path.join(base_path, subset, category)\n",
    "            for filename in os.listdir(folder_path):\n",
    "                if filename.endswith('.jpg'):\n",
    "                    file_path = os.path.join(folder_path, filename)\n",
    "                    # Upload Images\n",
    "                    image = load_img(file_path)\n",
    "                    image_array = img_to_array(image)\n",
    "                    # Add the data\n",
    "                    data['photo_id'].append(filename)\n",
    "                    data['image'].append(image)\n",
    "                    data['image_array'].append(image_array)\n",
    "                    data['malignant'].append(categories[category])\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "base_path = './images'\n",
    "df = load_images_to_df(base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   photo_id                                              image  \\\n",
      "0     1.jpg  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n",
      "1    10.jpg  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n",
      "2   100.jpg  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n",
      "3  1000.jpg  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n",
      "4  1001.jpg  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n",
      "\n",
      "                                         image_array  malignant  \n",
      "0  [[[181.0, 140.0, 144.0], [190.0, 149.0, 153.0]...          0  \n",
      "1  [[[231.0, 138.0, 156.0], [232.0, 139.0, 157.0]...          0  \n",
      "2  [[[144.0, 126.0, 138.0], [151.0, 133.0, 145.0]...          0  \n",
      "3  [[[238.0, 150.0, 174.0], [238.0, 150.0, 174.0]...          0  \n",
      "4  [[[211.0, 122.0, 142.0], [213.0, 124.0, 144.0]...          0  \n",
      "Number of rows in the DataFrame: 13879\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "row_count = len(df)\n",
    "print(\"Number of rows in the DataFrame:\", row_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to make augmentation of pics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_dir = './images/undetec_to_augm'\n",
    "train_augm_undetected_dir = './images/train/Undetected'\n",
    "test_augm_undetected_dir ='./images/test/Undetected'\n",
    "\n",
    "# Create a data generator for augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range = [0.8, 1.3],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# List the files in the original dataset directory\n",
    "file_list = os.listdir(original_dataset_dir)\n",
    "\n",
    "# Ensure the target directories exist\n",
    "os.makedirs(train_augm_undetected_dir, exist_ok=True)\n",
    "os.makedirs(test_augm_undetected_dir, exist_ok=True)\n",
    "\n",
    "# Desired number of images after augmentation\n",
    "target_count_1 = 6000\n",
    "target_count_2 = 1000\n",
    "\"\"\"= target_count_2 = target_count_3 = target_count_4 = target_count_5 = target_count_6 = target_count_7\"\"\"\n",
    "\n",
    "# Number of images in the original dataset\n",
    "original_count = len(file_list)\n",
    "\n",
    "\n",
    "# Number of times to repeat each image to reach the target count\n",
    "repeats_1 = min(target_count_1 // original_count + 1, len(file_list))\n",
    "repeats_2 = min(target_count_2 // original_count + 1, len(file_list))\n",
    "\"\"\"repeats_3 = min(target_count_3 // original_count + 1, len(file_list))\n",
    "repeats_4 = min(target_count_4 // original_count + 1, len(file_list))\n",
    "repeats_5 = min(target_count_5 // original_count + 1, len(file_list))\n",
    "repeats_6 = min(target_count_6 // original_count + 1, len(file_list))\n",
    "repeats_7 = min(target_count_7 // original_count + 1, len(file_list))\"\"\"\n",
    "\n",
    "# Augment and save the images for the 6000 train images\n",
    "for file in file_list[:original_count]:\n",
    "    img_path = os.path.join(original_dataset_dir, file)\n",
    "    img = load_img(img_path)\n",
    "    img = img_to_array(img)\n",
    "    img = img.reshape((1,) + img.shape)\n",
    "\n",
    "    i = 0\n",
    "    for batch in datagen.flow(img, batch_size=1, save_to_dir = train_augm_undetected_dir, save_prefix='augm', save_format='jpeg'): \n",
    "        #if in the previous line i save them as jpg, it anyway augments only the jpeg ones\n",
    "        i += 1\n",
    "        if i >= repeats_1:\n",
    "            break  # break the loop after reaching the desired number of augmented images\n",
    "\n",
    "\n",
    "\n",
    "# Augment and save the images for the 1000 test images\n",
    "for file in file_list[:original_count]:\n",
    "    img_path = os.path.join(original_dataset_dir, file)\n",
    "    img = load_img(img_path)\n",
    "    img = img_to_array(img)\n",
    "    img = img.reshape((1,) + img.shape)\n",
    "\n",
    "    i = 0\n",
    "    for batch in datagen.flow(img, batch_size=1, save_to_dir = test_augm_undetected_dir, save_prefix='aug', save_format='jpeg'):\n",
    "        i += 1\n",
    "        if i >= repeats_2:\n",
    "            break  # break the loop after reaching the desired number of augmented images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
