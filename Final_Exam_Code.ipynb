{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Final Exam Machine Learning","metadata":{}},{"cell_type":"markdown","source":"Davide Tateo; 167275\n\nFrancesca Salute; 167284\n\nNicole Favero; 167340 \n\nTomás Gonçalves; 167288","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/frasalute/ML_FinalExam.git","metadata":{"execution":{"iopub.status.busy":"2024-05-09T18:42:59.788911Z","iopub.execute_input":"2024-05-09T18:42:59.789281Z","iopub.status.idle":"2024-05-09T18:43:30.882692Z","shell.execute_reply.started":"2024-05-09T18:42:59.789240Z","shell.execute_reply":"2024-05-09T18:43:30.881695Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'ML_FinalExam'...\nremote: Enumerating objects: 22328, done.\u001b[K\nremote: Counting objects: 100% (8140/8140), done.\u001b[K\nremote: Compressing objects: 100% (8125/8125), done.\u001b[K\nremote: Total 22328 (delta 21), reused 8132 (delta 14), pack-reused 14188\u001b[K\nReceiving objects: 100% (22328/22328), 401.90 MiB | 22.81 MiB/s, done.\nResolving deltas: 100% (32/32), done.\nUpdating files: 100% (22257/22257), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nprint(f\"Current working directory: {os.getcwd()}\")\nprint(f\"Contents of the current directory: {os.listdir('.')}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-09T18:44:21.419344Z","iopub.execute_input":"2024-05-09T18:44:21.419722Z","iopub.status.idle":"2024-05-09T18:44:21.425512Z","shell.execute_reply.started":"2024-05-09T18:44:21.419690Z","shell.execute_reply":"2024-05-09T18:44:21.424619Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Current working directory: /kaggle/working\nContents of the current directory: ['ML_FinalExam', '.virtual_documents']\n","output_type":"stream"}]},{"cell_type":"code","source":"base_path = '/kaggle/working/ML_FinalExam/images'\nprint(\"Base path is:\", base_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T18:45:29.075435Z","iopub.execute_input":"2024-05-09T18:45:29.076113Z","iopub.status.idle":"2024-05-09T18:45:29.081108Z","shell.execute_reply.started":"2024-05-09T18:45:29.076082Z","shell.execute_reply":"2024-05-09T18:45:29.080205Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Base path is: /kaggle/working/ML_FinalExam/images\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        # Currently, memory growth needs to be the same across GPUs\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n    except RuntimeError as e:\n        # Memory growth must be set before GPUs have been initialized\n        print(e)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T18:44:43.599021Z","iopub.execute_input":"2024-05-09T18:44:43.600046Z","iopub.status.idle":"2024-05-09T18:44:43.788155Z","shell.execute_reply.started":"2024-05-09T18:44:43.600009Z","shell.execute_reply":"2024-05-09T18:44:43.787111Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#importing required API and modules\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom tensorflow.keras.utils import img_to_array\nfrom keras.preprocessing.image import array_to_img\nfrom tensorflow.keras.utils import load_img\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2024-05-09T18:44:50.179208Z","iopub.execute_input":"2024-05-09T18:44:50.179609Z","iopub.status.idle":"2024-05-09T18:44:50.186349Z","shell.execute_reply.started":"2024-05-09T18:44:50.179579Z","shell.execute_reply":"2024-05-09T18:44:50.184989Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def load_images_to_df(base_path):\n    data = {'photo_id': [], 'image': [], 'image_array' :[], 'malignant': []}\n    categories = {'Benign': 0, 'Malignant': 1}\n    \n    for subset in ['train', 'test']:\n        for category in ['Benign', 'Malignant']:\n            folder_path = os.path.join(base_path, subset, category)\n            for filename in os.listdir(folder_path):\n                if filename.endswith('.jpg'):\n                    file_path = os.path.join(folder_path, filename)\n                    # Upload Images\n                    image = load_img(file_path)\n                    image_array = img_to_array(image)\n                    # Add the data\n                    data['photo_id'].append(filename)\n                    data['image'].append(image)\n                    data['image_array'].append(image_array)\n                    data['malignant'].append(categories[category])\n    \n    # Create DataFrame\n    df = pd.DataFrame(data)\n    return df\n\n\ndf = load_images_to_df(base_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T18:45:44.984307Z","iopub.execute_input":"2024-05-09T18:45:44.985164Z","iopub.status.idle":"2024-05-09T18:46:01.737320Z","shell.execute_reply.started":"2024-05-09T18:45:44.985129Z","shell.execute_reply":"2024-05-09T18:46:01.736303Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(df.head())\nrow_count = len(df)\nprint(\"Number of rows in the DataFrame:\", row_count)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T18:46:18.954209Z","iopub.execute_input":"2024-05-09T18:46:18.954601Z","iopub.status.idle":"2024-05-09T18:46:27.000728Z","shell.execute_reply.started":"2024-05-09T18:46:18.954570Z","shell.execute_reply":"2024-05-09T18:46:26.999665Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"   photo_id                                              image  \\\n0  6057.jpg  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n1  2639.jpg  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n2  2655.jpg  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n3  1880.jpg  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n4  3100.jpg  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n\n                                         image_array  malignant  \n0  [[[117.0, 85.0, 70.0], [118.0, 86.0, 71.0], [1...          0  \n1  [[[197.0, 163.0, 188.0], [198.0, 164.0, 189.0]...          0  \n2  [[[182.0, 129.0, 125.0], [180.0, 127.0, 123.0]...          0  \n3  [[[147.0, 102.0, 109.0], [113.0, 68.0, 75.0], ...          0  \n4  [[[162.0, 109.0, 119.0], [166.0, 113.0, 123.0]...          0  \nNumber of rows in the DataFrame: 13879\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Code to make augmentation of pics","metadata":{}},{"cell_type":"code","source":"'''original_dataset_dir = './images/undetec_to_augm'\ntrain_augm_undetected_dir = './images/train/Undetected'\ntest_augm_undetected_dir ='./images/test/Undetected'\n\n# Create a data generator for augmentation\ndatagen = ImageDataGenerator(\n    rotation_range=30,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    brightness_range = [0.8, 1.3],\n    fill_mode='nearest'\n)\n\n# List the files in the original dataset directory\nfile_list = os.listdir(original_dataset_dir)\n\n# Ensure the target directories exist\nos.makedirs(train_augm_undetected_dir, exist_ok=True)\nos.makedirs(test_augm_undetected_dir, exist_ok=True)\n\n# Desired number of images after augmentation\ntarget_count_1 = 6000\ntarget_count_2 = 1000\n\"\"\"= target_count_2 = target_count_3 = target_count_4 = target_count_5 = target_count_6 = target_count_7\"\"\"\n\n# Number of images in the original dataset\noriginal_count = len(file_list)\n\n\n# Number of times to repeat each image to reach the target count\nrepeats_1 = min(target_count_1 // original_count + 1, len(file_list))\nrepeats_2 = min(target_count_2 // original_count + 1, len(file_list))\n\"\"\"repeats_3 = min(target_count_3 // original_count + 1, len(file_list))\nrepeats_4 = min(target_count_4 // original_count + 1, len(file_list))\nrepeats_5 = min(target_count_5 // original_count + 1, len(file_list))\nrepeats_6 = min(target_count_6 // original_count + 1, len(file_list))\nrepeats_7 = min(target_count_7 // original_count + 1, len(file_list))\"\"\"\n\n# Augment and save the images for the 6000 train images\nfor file in file_list[:original_count]:\n    img_path = os.path.join(original_dataset_dir, file)\n    img = load_img(img_path)\n    img = img_to_array(img)\n    img = img.reshape((1,) + img.shape)\n\n    i = 0\n    for batch in datagen.flow(img, batch_size=1, save_to_dir = train_augm_undetected_dir, save_prefix='augm', save_format='jpeg'): \n        #if in the previous line i save them as jpg, it anyway augments only the jpeg ones\n        i += 1\n        if i >= repeats_1:\n            break  # break the loop after reaching the desired number of augmented images\n\n\n\n# Augment and save the images for the 1000 test images\nfor file in file_list[:original_count]:\n    img_path = os.path.join(original_dataset_dir, file)\n    img = load_img(img_path)\n    img = img_to_array(img)\n    img = img.reshape((1,) + img.shape)\n\n    i = 0\n    for batch in datagen.flow(img, batch_size=1, save_to_dir = test_augm_undetected_dir, save_prefix='aug', save_format='jpeg'):\n        i += 1\n        if i >= repeats_2:\n            break  # break the loop after reaching the desired number of augmented images '''","metadata":{},"execution_count":10,"outputs":[]}]}