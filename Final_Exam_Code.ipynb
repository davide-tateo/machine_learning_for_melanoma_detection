{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"papermill":{"duration":0.004634,"end_time":"2024-05-09T20:22:05.309483","exception":false,"start_time":"2024-05-09T20:22:05.304849","status":"completed"},"tags":[]},"source":["## Final Exam Machine Learning"]},{"attachments":{},"cell_type":"markdown","id":"26d770b5","metadata":{"papermill":{"duration":0.003633,"end_time":"2024-05-09T20:22:05.317362","exception":false,"start_time":"2024-05-09T20:22:05.313729","status":"completed"},"tags":[]},"source":["Davide Tateo; 167275\n","\n","Francesca Salute; 167284\n","\n","Nicole Favero; 167340 \n","\n","Tomás Gonçalves; 167288"]},{"cell_type":"markdown","metadata":{},"source":["# Preparation "]},{"cell_type":"code","execution_count":1,"id":"c01b779b","metadata":{"execution":{"iopub.execute_input":"2024-05-10T18:08:40.949064Z","iopub.status.busy":"2024-05-10T18:08:40.948741Z","iopub.status.idle":"2024-05-10T18:09:09.501056Z","shell.execute_reply":"2024-05-10T18:09:09.499950Z","shell.execute_reply.started":"2024-05-10T18:08:40.949036Z"},"papermill":{"duration":25.36528,"end_time":"2024-05-09T20:22:30.686398","exception":false,"start_time":"2024-05-09T20:22:05.321118","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'ML_FinalExam'...\n","remote: Enumerating objects: 22346, done.\u001b[K\n","remote: Counting objects: 100% (8158/8158), done.\u001b[K\n","remote: Compressing objects: 100% (8143/8143), done.\u001b[K\n","remote: Total 22346 (delta 31), reused 8132 (delta 14), pack-reused 14188\u001b[K\n","Receiving objects: 100% (22346/22346), 401.91 MiB | 27.38 MiB/s, done.\n","Resolving deltas: 100% (42/42), done.\n","Updating files: 100% (22257/22257), done.\n"]}],"source":["#!git clone https://github.com/frasalute/ML_FinalExam.git"]},{"cell_type":"code","execution_count":1,"id":"7a3b910d","metadata":{"execution":{"iopub.execute_input":"2024-05-10T18:09:09.503406Z","iopub.status.busy":"2024-05-10T18:09:09.503084Z","iopub.status.idle":"2024-05-10T18:09:09.509111Z","shell.execute_reply":"2024-05-10T18:09:09.508194Z","shell.execute_reply.started":"2024-05-10T18:09:09.503378Z"},"papermill":{"duration":0.02752,"end_time":"2024-05-09T20:22:30.733003","exception":false,"start_time":"2024-05-09T20:22:30.705483","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Current working directory: c:\\Users\\davit\\Desktop\\CBS\\MACHINE LEARNING\\GithubExam\\ML_FinalExam\n","Contents of the current directory: ['.DS_Store', '.git', 'Final_Exam_Code.ipynb', 'images', 'LICENSE', 'README.md']\n"]}],"source":["import os\n","print(f\"Current working directory: {os.getcwd()}\")\n","print(f\"Contents of the current directory: {os.listdir('.')}\")"]},{"cell_type":"code","execution_count":3,"id":"16362855","metadata":{"execution":{"iopub.execute_input":"2024-05-10T18:09:09.510546Z","iopub.status.busy":"2024-05-10T18:09:09.510247Z","iopub.status.idle":"2024-05-10T18:09:09.519289Z","shell.execute_reply":"2024-05-10T18:09:09.518454Z","shell.execute_reply.started":"2024-05-10T18:09:09.510523Z"},"papermill":{"duration":0.037028,"end_time":"2024-05-09T20:22:30.788959","exception":false,"start_time":"2024-05-09T20:22:30.751931","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Base path is: /kaggle/working/ML_FinalExam/images\n"]}],"source":["base_path = '/work/ML_FinalExam/images'\n","print(\"Base path is:\", base_path)"]},{"cell_type":"code","execution_count":null,"id":"663cd4c7","metadata":{},"outputs":[],"source":["# pip install tensorflow\n","# pip install scikit-learn\n","# pip install seaborn\n","# pip install imagehash\n","# pip install keras-tuner"]},{"cell_type":"code","execution_count":5,"id":"8ada059f","metadata":{"execution":{"iopub.execute_input":"2024-05-10T18:09:20.961275Z","iopub.status.busy":"2024-05-10T18:09:20.960741Z","iopub.status.idle":"2024-05-10T18:09:20.969758Z","shell.execute_reply":"2024-05-10T18:09:20.968699Z","shell.execute_reply.started":"2024-05-10T18:09:20.961247Z"},"papermill":{"duration":0.030045,"end_time":"2024-05-09T20:22:44.024258","exception":false,"start_time":"2024-05-09T20:22:43.994213","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Importing required API and modules\n","import warnings\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.utils import img_to_array\n","from keras.preprocessing.image import array_to_img\n","from tensorflow.keras.utils import load_img\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import imagehash\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","import time\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report, accuracy_score\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import learning_curve, StratifiedKFold\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n","from kerastuner import RandomSearch\n","from kerastuner.tuners import RandomSearch"]},{"cell_type":"code","execution_count":4,"id":"c40083af","metadata":{"execution":{"iopub.execute_input":"2024-05-10T18:09:09.521490Z","iopub.status.busy":"2024-05-10T18:09:09.521163Z","iopub.status.idle":"2024-05-10T18:09:20.959571Z","shell.execute_reply":"2024-05-10T18:09:20.958687Z","shell.execute_reply.started":"2024-05-10T18:09:09.521449Z"},"papermill":{"duration":13.163557,"end_time":"2024-05-09T20:22:43.976467","exception":false,"start_time":"2024-05-09T20:22:30.812910","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-05-10 18:09:11.097988: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-10 18:09:11.098083: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-10 18:09:11.217698: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        # Currently, memory growth needs to be the same across GPUs\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","    except RuntimeError as e:\n","        # Memory growth must be set before GPUs have been initialized\n","        print(e)"]},{"attachments":{},"cell_type":"markdown","id":"ee86a5e4","metadata":{},"source":["# Loading the data - Resizing will be done after the filtering"]},{"cell_type":"code","execution_count":6,"id":"9f3f07cf","metadata":{"execution":{"iopub.execute_input":"2024-05-10T18:09:20.971501Z","iopub.status.busy":"2024-05-10T18:09:20.971183Z","iopub.status.idle":"2024-05-10T18:09:37.961718Z","shell.execute_reply":"2024-05-10T18:09:37.960866Z","shell.execute_reply.started":"2024-05-10T18:09:20.971472Z"},"papermill":{"duration":16.952118,"end_time":"2024-05-09T20:23:00.994037","exception":false,"start_time":"2024-05-09T20:22:44.041919","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def load_images(base_path, categories):\n","    data = {'photo_id': [], 'image': [], 'category': [], 'subset': []}\n","    \n","    for subset in ['train', 'test']:\n","        for category in categories.keys():\n","            folder_path = os.path.join(base_path, subset, category)\n","            for filename in os.listdir(folder_path):\n","                if filename.lower().endswith(('.jpg', '.jpeg')):  # Check for both .jpg and .jpeg extensions\n","                    file_path = os.path.join(folder_path, filename)\n","                    # Load the image\n","                    image = load_img(file_path)\n","                    # Add data to the DataFrame\n","                    data['photo_id'].append(filename)\n","                    data['image'].append(image)\n","                    data['category'].append(categories[category])\n","                    data['subset'].append(subset)\n","    \n","    df = pd.DataFrame(data)\n","    return df\n","\n","# Load the DataFrame\n","categories = {'Benign': 0, 'Malignant': 1, 'Undetected': 2}\n","base_path = '/work/ML_FinalExam/images'\n","df = load_images(base_path, categories)"]},{"cell_type":"code","execution_count":7,"id":"527f6db1","metadata":{"execution":{"iopub.execute_input":"2024-05-10T18:09:37.963115Z","iopub.status.busy":"2024-05-10T18:09:37.962823Z","iopub.status.idle":"2024-05-10T18:09:45.968376Z","shell.execute_reply":"2024-05-10T18:09:45.967399Z","shell.execute_reply.started":"2024-05-10T18:09:37.963091Z"},"papermill":{"duration":8.100521,"end_time":"2024-05-09T20:23:09.114178","exception":false,"start_time":"2024-05-09T20:23:01.013657","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["   photo_id                                              image  \\\n","0  6154.jpg  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n","1  3582.jpg  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n","2  2657.jpg  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n","3     2.jpg  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n","4  4941.jpg  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n","\n","                                         image_array  category  \n","0  [[[170.0, 129.0, 145.0], [172.0, 131.0, 147.0]...         0  \n","1  [[[140.0, 108.0, 87.0], [141.0, 109.0, 88.0], ...         0  \n","2  [[[170.0, 130.0, 156.0], [174.0, 134.0, 160.0]...         0  \n","3  [[[253.0, 202.0, 245.0], [255.0, 205.0, 248.0]...         0  \n","4  [[[182.0, 144.0, 155.0], [183.0, 145.0, 156.0]...         0  \n","Number of rows in the DataFrame: 13879\n"]}],"source":["print(df.head())\n","row_count = len(df)\n","print(\"Number of rows in the DataFrame:\", row_count)"]},{"cell_type":"code","execution_count":null,"id":"0c06b89f","metadata":{},"outputs":[],"source":["# Category Distribution Bar Chart showing for Benign, Malignant and Undetected how many images belong to each\n","\n","plt.figure(figsize=(10, 7))\n","sns.countplot(data=df, x='category')\n","plt.title('Category Distribution') # Presenting the different categories of the dataset and the number of images in those categories\n","plt.xlabel('Category')\n","plt.ylabel('Number of Images')\n","plt.xticks(ticks=[0, 1, 2], labels=['Benign', 'Malignant', 'Undetected'])  \n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"29e0f7e0","metadata":{},"outputs":[],"source":["# Subset Distribution Bar Chart showing for Trial and Test how many images belong to each\n","\n","plt.figure(figsize=(10, 7))\n","sns.countplot(data=df, x='subset')\n","plt.title('Subset Distribution') # Presenting the two subsets of the dataset and the number of images belonging to each subsets\n","plt.xlabel('Subset')\n","plt.ylabel('Number of Images')\n","plt.xticks(ticks=[0, 1], labels=['Train', 'Test'])  \n","plt.show()"]},{"attachments":{},"cell_type":"markdown","id":"401082fc","metadata":{"papermill":{"duration":0.016977,"end_time":"2024-05-09T20:23:09.148992","exception":false,"start_time":"2024-05-09T20:23:09.132015","status":"completed"},"tags":[]},"source":["# Augmentation of \"undetected\" datasets"]},{"cell_type":"code","execution_count":8,"id":"f3edf820","metadata":{"execution":{"iopub.execute_input":"2024-05-10T18:09:45.970020Z","iopub.status.busy":"2024-05-10T18:09:45.969685Z","iopub.status.idle":"2024-05-10T18:09:45.980497Z","shell.execute_reply":"2024-05-10T18:09:45.979563Z","shell.execute_reply.started":"2024-05-10T18:09:45.969993Z"},"papermill":{"duration":0.035787,"end_time":"2024-05-09T20:23:09.204724","exception":false,"start_time":"2024-05-09T20:23:09.168937","status":"completed"},"tags":[],"trusted":true},"outputs":[{"data":{"text/plain":["'original_dataset_dir = \\'./images/undetec_to_augm\\'\\ntrain_augm_undetected_dir = \\'./images/train/Undetected\\'\\ntest_augm_undetected_dir =\\'./images/test/Undetected\\'\\n\\n# Create a data generator for augmentation\\ndatagen = ImageDataGenerator(\\n    rotation_range=30,\\n    width_shift_range=0.2,\\n    height_shift_range=0.2,\\n    shear_range=0.2,\\n    zoom_range=0.2,\\n    horizontal_flip=True,\\n    brightness_range = [0.8, 1.3],\\n    fill_mode=\\'nearest\\'\\n)\\n\\n# List the files in the original dataset directory\\nfile_list = os.listdir(original_dataset_dir)\\n\\n# Ensure the target directories exist\\nos.makedirs(train_augm_undetected_dir, exist_ok=True)\\nos.makedirs(test_augm_undetected_dir, exist_ok=True)\\n\\n# Desired number of images after augmentation\\ntarget_count_1 = 6000\\ntarget_count_2 = 1000\\n\"\"\"= target_count_2 = target_count_3 = target_count_4 = target_count_5 = target_count_6 = target_count_7\"\"\"\\n\\n# Number of images in the original dataset\\noriginal_count = len(file_list)\\n\\n\\n# Number of times to repeat each image to reach the target count\\nrepeats_1 = min(target_count_1 // original_count + 1, len(file_list))\\nrepeats_2 = min(target_count_2 // original_count + 1, len(file_list))\\n\"\"\"repeats_3 = min(target_count_3 // original_count + 1, len(file_list))\\nrepeats_4 = min(target_count_4 // original_count + 1, len(file_list))\\nrepeats_5 = min(target_count_5 // original_count + 1, len(file_list))\\nrepeats_6 = min(target_count_6 // original_count + 1, len(file_list))\\nrepeats_7 = min(target_count_7 // original_count + 1, len(file_list))\"\"\"\\n\\n# Augment and save the images for the 6000 train images\\nfor file in file_list[:original_count]:\\n    img_path = os.path.join(original_dataset_dir, file)\\n    img = load_img(img_path)\\n    img = img_to_array(img)\\n    img = img.reshape((1,) + img.shape)\\n\\n    i = 0\\n    for batch in datagen.flow(img, batch_size=1, save_to_dir = train_augm_undetected_dir, save_prefix=\\'augm\\', save_format=\\'jpeg\\'): \\n        #if in the previous line i save them as jpg, it anyway augments only the jpeg ones\\n        i += 1\\n        if i >= repeats_1:\\n            break  # break the loop after reaching the desired number of augmented images\\n\\n\\n\\n# Augment and save the images for the 1000 test images\\nfor file in file_list[:original_count]:\\n    img_path = os.path.join(original_dataset_dir, file)\\n    img = load_img(img_path)\\n    img = img_to_array(img)\\n    img = img.reshape((1,) + img.shape)\\n\\n    i = 0\\n    for batch in datagen.flow(img, batch_size=1, save_to_dir = test_augm_undetected_dir, save_prefix=\\'aug\\', save_format=\\'jpeg\\'):\\n        i += 1\\n        if i >= repeats_2:\\n            break  # break the loop after reaching the desired number of augmented images '"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Set the source directory and the target directories\n","original_undetected_dir = './images/undetec_to_augm'\n","train_augm_undetected_dir = './images/train/Undetected'\n","test_augm_undetected_dir ='./images/test/Undetected'\n","\n","# Create a data generator for augmentation\n","datagen = ImageDataGenerator(\n","    rotation_range=30,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    brightness_range = [0.8, 1.3],\n","    fill_mode='nearest'\n",")\n","\n","def augment_img_dataset(source_dir, target_dir, target_count, imagedata_generator):\n","\n","    \"\"\"\n","        #this function performs augmentation\n","\n","        # source_dir:           directory containing the original dataset to augment\n","        # target_dir:           directory where to save the augmented images\n","        # target_count:         desired number of images after augmentation\n","        # imagedata_generator:  image data generator object to be used for aumentation\n","\n","        # returns:              augmented set of images\n","    \"\"\" \n","\n","    # List the files in the source directory containing the original dataset \n","    file_list = os.listdir(source_dir)\n","    # Number of images in the original dataset\n","    original_count = len(file_list)\n","\n","    # Number of times to repeat each image to reach the target count\n","    repeats_1 = min(target_count // original_count + 1, len(file_list))\n","\n","    # Ensure the target directories exist\n","    os.makedirs(target_dir, exist_ok=True)    \n","\n","    # Augment and save the images for the 6000 train images\n","    for file in file_list:\n","        img_path = os.path.join(source_dir, file)\n","        img = load_img(img_path)\n","        img = img_to_array(img)\n","        img = img.reshape((1,) + img.shape)\n","\n","        i = 0\n","        for batch in imagedata_generator.flow(img, batch_size=1, save_to_dir = target_dir, save_prefix='augm', save_format='jpeg'): \n","            #if in the previous line i save them as jpg, it anyway augments only the jpeg ones\n","            i += 1\n","            if i >= repeats_1:\n","                break  # break the loop after reaching the desired number of augmented images\n","\n","### AVOID RUNNING THE FOLLOWING IF DATASET HAS ALREADY BEEN AUGMENTED ###\n","            \n","# Perform augmentation to expand the train and test datasets for \"undetected\"\n","    #augment_img_dataset(original_undetected_dir, train_augm_undetected_dir, 6000, datagen)\n","    #augment_img_dataset(original_undetected_dir, test_augm_undetected_dir, 1000, datagen)"]},{"attachments":{},"cell_type":"markdown","id":"1a72f3fb","metadata":{},"source":["# Filtering"]},{"attachments":{},"cell_type":"markdown","id":"b485f6c4","metadata":{},"source":["Checking for Duplicates"]},{"cell_type":"code","execution_count":null,"id":"21d03ae4","metadata":{},"outputs":[],"source":["# Compute different types of hashes for each image and add to DataFrame\n","def compute_hashes(df):\n","    a_hashes = []\n","    d_hashes = []\n","    w_hashes = []\n","    for image in df['image']:\n","        # No need to convert to array, directly use the PIL image object\n","        a_hashes.append(str(imagehash.average_hash(image)))\n","        d_hashes.append(str(imagehash.dhash(image)))\n","        w_hashes.append(str(imagehash.whash(image)))\n","    df['a_hash'] = a_hashes\n","    df['d_hash'] = d_hashes\n","    df['w_hash'] = w_hashes\n","\n","compute_hashes(df)\n","\n","# Check for duplicates based on different hashes\n","duplicate_a_hash = df[df.duplicated(subset='a_hash', keep=False)]\n","duplicate_d_hash = df[df.duplicated(subset='d_hash', keep=False)]\n","duplicate_w_hash = df[df.duplicated(subset='w_hash', keep=False)]\n","\n","print(\"Duplicate Images based on Average Hash:\")\n","print(duplicate_a_hash[['photo_id', 'category', 'subset', 'a_hash']])\n","\n","print(\"Duplicate Images based on Difference Hash:\")\n","print(duplicate_d_hash[['photo_id', 'category', 'subset', 'd_hash']])\n","\n","print(\"Duplicate Images based on Wavelet Hash:\")\n","print(duplicate_w_hash[['photo_id', 'category', 'subset', 'w_hash']])\n"]},{"cell_type":"code","execution_count":null,"id":"3c922fd5","metadata":{},"outputs":[],"source":["# Function to visualize duplicate images\n","def visualize_duplicates(df, hash_column):\n","    duplicates = df[df.duplicated(subset=hash_column, keep=False)]\n","    grouped = duplicates.groupby(hash_column)\n","    for hash_value, group in grouped:\n","        if len(group) > 1:\n","            fig, axes = plt.subplots(1, len(group), figsize=(15, 5))\n","            for ax, (_, row) in zip(axes, group.iterrows()):\n","                ax.imshow(row['image'])\n","                ax.set_title(f\"{row['photo_id']}\\n{row['category']}\\n{row['subset']}\")\n","                ax.axis('off')\n","            plt.suptitle(f\"Duplicates based on {hash_column}: {hash_value}\")\n","            plt.show()\n","\n","# Visualize duplicates for each hash type\n","visualize_duplicates(df, 'a_hash')\n","visualize_duplicates(df, 'd_hash')\n","visualize_duplicates(df, 'w_hash')"]},{"cell_type":"code","execution_count":null,"id":"51ae60e2","metadata":{},"outputs":[],"source":["# Manually specify the photo_id values to remove\n","photo_ids_to_remove = [\n","    '62.jpg', '1075.jpg', '341.jpg', '217.jpg', '1460.jpg', '410.jpg', '4035.jpg', \n","    '2265.jpg', '155.jpg', '305.jpg', '1108.jpg', '2288.jpg', '1193.jpg', '943.jpg', \n","    '2266.jpg', '883.jpg', '362.jpg', '890.jpg', '1089.jpg', '1497.jpg', '3410.jpg', \n","    '1172.jpg', '3255.jpg', '526.jpg', '286.jpg', '3190.jpg', '2083.jpg', '522.jpg', \n","    '104.jpg', '2076.jpg', '384.jpg', '1458.jpg', '248.jpg', '415.jpg', '189.jpg', \n","    '323.jpg', '112.jpg', '375.jpg', '178.jpg', '1316.jpg', '2096.jpg', '118.jpg', \n","    '250.jpg', '49.jpg', '294.jpg', '417.jpg', '1153.jpg', '5366.jpg', '432.jpg', \n","    '874.jpg', '71.jpg'\n","]\n","\n","# Remove the specified duplicates from the DataFrame\n","df_cleaned = df[~df['photo_id'].isin(photo_ids_to_remove)]\n","\n","# Count images per category before and after removal of duplicates\n","def count_images_per_category(df):\n","    return df['category'].value_counts()\n","\n","print(\"Image count per category before removal:\")\n","print(count_images_per_category(df))\n","\n","print(\"Image count per category after removal:\")\n","print(count_images_per_category(df_cleaned))\n","\n","print(f\"Original DataFrame size: {len(df)}\")\n","print(f\"Cleaned DataFrame size: {len(df_cleaned)}\")\n","\n","df = df_cleaned"]},{"attachments":{},"cell_type":"markdown","id":"de023a59","metadata":{},"source":["Check the size of the images before resize them"]},{"cell_type":"code","execution_count":null,"id":"1bc91d5b","metadata":{},"outputs":[],"source":["# Function to calculate the aspect ratio of an image\n","def aspect_ratio(image):\n","    width, height = image.size\n","    return width / height\n","\n","# Function to filter images based on aspect ratio\n","def filter_aspect_ratio(df_cleaned):\n","    filtered_df = df_cleaned[df_cleaned.apply(lambda row: 0.25 <= aspect_ratio(row['image']) <= 4.0, axis=1)]\n","    return filtered_df\n","\n","# Apply the aspect ratio filter to the DataFrame\n","df_aspect_filtered = filter_aspect_ratio(df_cleaned)\n","\n","print(f\"Original DataFrame size: {len(df_cleaned)}\")\n","print(f\"Aspect Ratio Filtered DataFrame size: {len(df_aspect_filtered)}\")"]},{"attachments":{},"cell_type":"markdown","id":"47d8432d","metadata":{},"source":["Check the average RGB values"]},{"cell_type":"code","execution_count":null,"id":"e68de57c","metadata":{},"outputs":[],"source":["# Function to calculate the average RGB values of an image\n","def average_rgb(image):\n","    np_image = np.array(image)\n","    avg_r = np.mean(np_image[:, :, 0])\n","    avg_g = np.mean(np_image[:, :, 1])\n","    avg_b = np.mean(np_image[:, :, 2])\n","    return avg_r, avg_g, avg_b\n","\n","# Function to filter images based on average RGB values and return filtered out images\n","def filter_rgb_values(df):\n","    filtered_out_indices = []\n","    for idx, row in df.iterrows():\n","        avg_r, avg_g, avg_b = average_rgb(row['image'])\n","        if not (5 <= avg_r <= 250 and 5 <= avg_g <= 250 and 5 <= avg_b <= 250):\n","            filtered_out_indices.append(idx)\n","    filtered_out_df = df.loc[filtered_out_indices]\n","    filtered_df = df.drop(filtered_out_indices)\n","    return filtered_df, filtered_out_df\n","\n","# Apply the RGB value filter to the aspect ratio filtered DataFrame\n","df_final_filtered, df_filtered_out = filter_rgb_values(df_aspect_filtered)\n","\n","print(f\"Aspect Ratio Filtered DataFrame size: {len(df_aspect_filtered)}\")\n","print(f\"Final Filtered DataFrame size: {len(df_final_filtered)}\")\n","print(f\"Filtered Out DataFrame size: {len(df_filtered_out)}\")\n","\n","# Function to visualize filtered out images\n","def visualize_filtered_images(df):\n","    for idx, row in df.iterrows():\n","        image = row['image']\n","        plt.imshow(image)\n","        plt.title(f\"Photo ID: {row['photo_id']}\\nCategory: {row['category']}\\nSubset: {row['subset']}\")\n","        plt.axis('off')\n","        plt.show()\n","\n","# Visualize the filtered out images\n","visualize_filtered_images(df_filtered_out)"]},{"attachments":{},"cell_type":"markdown","id":"ae740f0a","metadata":{},"source":["Resize the images to 128 x 128 pixel"]},{"cell_type":"code","execution_count":null,"id":"10629764","metadata":{},"outputs":[],"source":["def resize_images(df, target_size=(128, 128)): \n","    for index, row in df.iterrows():\n","        image = row['image']\n","        # Resize the image\n","        resized_image = image.resize(target_size)\n","        image_array = img_to_array(resized_image)\n","        # Overwrite data in the original DataFrame\n","        df.at[index, 'image'] = resized_image\n","        df.at[index, 'image_array'] = image_array\n","    \n","    return df\n","\n","# Resize the images\n","df = resize_images(df)"]},{"cell_type":"code","execution_count":null,"id":"58791c2c","metadata":{},"outputs":[],"source":["# Presenting the above graphs again to show differences between before and after filtering\n","\n","# Category Distribution Bar Chart showing for Benign, Malignant and Undetected how many images belong to each \n","\n","plt.figure(figsize=(10, 7))\n","sns.countplot(data=df, x='category')\n","plt.title('Category Distribution') # Presenting the different categories of the dataset and the number of images in those categories\n","plt.xlabel('Category')\n","plt.ylabel('Number of Images')\n","plt.xticks(ticks=[0, 1, 2], labels=['Benign', 'Malignant', 'Undetected'])  \n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"131cf206","metadata":{},"outputs":[],"source":["# Subset Distribution Bar Chart showing for Trial and Test how many images belong to each\n","\n","plt.figure(figsize=(10, 7))\n","sns.countplot(data=df, x='subset')\n","plt.title('Subset Distribution') # Presenting the two subsets of the dataset and the number of images belonging to each subsets\n","plt.xlabel('Subset')\n","plt.ylabel('Number of Images')\n","plt.xticks(ticks=[0, 1], labels=['Train', 'Test'])  \n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"3fb8ef5f","metadata":{},"outputs":[],"source":["# Color Matrix"]},{"attachments":{},"cell_type":"markdown","id":"79ca2ef7","metadata":{},"source":["# PCA"]},{"cell_type":"code","execution_count":11,"id":"916d5035","metadata":{"execution":{"iopub.execute_input":"2024-05-10T18:09:46.848363Z","iopub.status.busy":"2024-05-10T18:09:46.847987Z","iopub.status.idle":"2024-05-10T18:09:49.275234Z","shell.execute_reply":"2024-05-10T18:09:49.274327Z","shell.execute_reply.started":"2024-05-10T18:09:46.848332Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[[170. 129. 145.]\n","   [172. 131. 147.]\n","   [170. 129. 145.]\n","   ...\n","   [202. 167. 174.]\n","   [200. 165. 172.]\n","   [199. 164. 171.]]\n","\n","  [[169. 128. 144.]\n","   [171. 130. 146.]\n","   [172. 131. 147.]\n","   ...\n","   [202. 167. 174.]\n","   [200. 165. 172.]\n","   [199. 164. 171.]]\n","\n","  [[170. 129. 145.]\n","   [171. 130. 146.]\n","   [173. 132. 146.]\n","   ...\n","   [202. 167. 174.]\n","   [201. 166. 173.]\n","   [199. 164. 171.]]\n","\n","  ...\n","\n","  [[176. 144. 149.]\n","   [179. 147. 152.]\n","   [183. 148. 154.]\n","   ...\n","   [195. 159. 163.]\n","   [193. 157. 161.]\n","   [191. 155. 159.]]\n","\n","  [[174. 142. 147.]\n","   [177. 145. 150.]\n","   [182. 147. 153.]\n","   ...\n","   [196. 160. 164.]\n","   [193. 157. 161.]\n","   [191. 155. 159.]]\n","\n","  [[173. 141. 146.]\n","   [176. 144. 149.]\n","   [181. 146. 152.]\n","   ...\n","   [195. 159. 163.]\n","   [193. 157. 161.]\n","   [190. 154. 158.]]]\n","\n","\n"," [[[140. 108.  87.]\n","   [141. 109.  88.]\n","   [143. 111.  90.]\n","   ...\n","   [133. 100.  85.]\n","   [147. 114.  99.]\n","   [137. 104.  89.]]\n","\n","  [[140. 108.  87.]\n","   [141. 109.  88.]\n","   [143. 111.  90.]\n","   ...\n","   [134. 101.  86.]\n","   [147. 114.  99.]\n","   [138. 105.  90.]]\n","\n","  [[140. 108.  87.]\n","   [141. 109.  88.]\n","   [143. 111.  90.]\n","   ...\n","   [133. 100.  85.]\n","   [147. 114.  99.]\n","   [138. 105.  90.]]\n","\n","  ...\n","\n","  [[130. 113.  87.]\n","   [126. 109.  83.]\n","   [127. 110.  84.]\n","   ...\n","   [143. 117. 100.]\n","   [140. 114.  97.]\n","   [136. 110.  93.]]\n","\n","  [[130. 114.  88.]\n","   [125. 109.  83.]\n","   [126. 109.  83.]\n","   ...\n","   [143. 117. 100.]\n","   [140. 114.  97.]\n","   [134. 108.  91.]]\n","\n","  [[130. 114.  88.]\n","   [125. 109.  83.]\n","   [126. 109.  83.]\n","   ...\n","   [143. 117. 100.]\n","   [139. 113.  96.]\n","   [134. 108.  91.]]]\n","\n","\n"," [[[170. 130. 156.]\n","   [174. 134. 160.]\n","   [180. 140. 166.]\n","   ...\n","   [172. 125. 145.]\n","   [170. 125. 145.]\n","   [172. 127. 147.]]\n","\n","  [[173. 133. 159.]\n","   [176. 136. 162.]\n","   [179. 139. 165.]\n","   ...\n","   [175. 128. 148.]\n","   [177. 132. 152.]\n","   [181. 136. 156.]]\n","\n","  [[176. 136. 162.]\n","   [177. 137. 163.]\n","   [178. 138. 164.]\n","   ...\n","   [180. 133. 153.]\n","   [185. 140. 160.]\n","   [190. 145. 165.]]\n","\n","  ...\n","\n","  [[162. 120. 140.]\n","   [162. 120. 140.]\n","   [160. 118. 138.]\n","   ...\n","   [170. 121. 140.]\n","   [167. 120. 138.]\n","   [167. 120. 138.]]\n","\n","  [[162. 120. 140.]\n","   [162. 120. 140.]\n","   [159. 117. 137.]\n","   ...\n","   [168. 119. 138.]\n","   [167. 120. 138.]\n","   [171. 124. 142.]]\n","\n","  [[162. 120. 140.]\n","   [161. 119. 139.]\n","   [158. 116. 136.]\n","   ...\n","   [167. 118. 137.]\n","   [167. 120. 138.]\n","   [173. 126. 144.]]]\n","\n","\n"," ...\n","\n","\n"," [[[  0.   0.   0.]\n","   [  0.   0.   0.]\n","   [  0.   0.   0.]\n","   ...\n","   [  0.   0.   0.]\n","   [  0.   0.   0.]\n","   [  0.   0.   0.]]\n","\n","  [[  0.   0.   0.]\n","   [  0.   0.   0.]\n","   [  0.   0.   0.]\n","   ...\n","   [  0.   0.   0.]\n","   [  0.   0.   0.]\n","   [  0.   0.   0.]]\n","\n","  [[  0.   0.   0.]\n","   [  0.   0.   0.]\n","   [  0.   0.   0.]\n","   ...\n","   [  0.   0.   0.]\n","   [  0.   0.   0.]\n","   [  0.   0.   0.]]\n","\n","  ...\n","\n","  [[  0.   0.   0.]\n","   [  0.   0.   0.]\n","   [  0.   0.   0.]\n","   ...\n","   [  1.   1.   1.]\n","   [  1.   1.   1.]\n","   [  1.   1.   1.]]\n","\n","  [[  0.   0.   0.]\n","   [  0.   0.   0.]\n","   [  0.   0.   0.]\n","   ...\n","   [  1.   1.   1.]\n","   [  1.   1.   1.]\n","   [  1.   1.   1.]]\n","\n","  [[  0.   0.   0.]\n","   [  0.   0.   0.]\n","   [  0.   0.   0.]\n","   ...\n","   [  1.   1.   1.]\n","   [  1.   1.   1.]\n","   [  1.   1.   1.]]]\n","\n","\n"," [[[158. 136. 138.]\n","   [152. 131. 128.]\n","   [151. 126. 121.]\n","   ...\n","   [145. 133. 121.]\n","   [135. 122. 114.]\n","   [131. 121. 112.]]\n","\n","  [[158. 136. 138.]\n","   [153. 129. 127.]\n","   [150. 125. 118.]\n","   ...\n","   [154. 140. 129.]\n","   [134. 121. 113.]\n","   [120. 110. 101.]]\n","\n","  [[159. 135. 135.]\n","   [152. 128. 126.]\n","   [148. 123. 116.]\n","   ...\n","   [161. 147. 136.]\n","   [140. 127. 119.]\n","   [121. 108. 100.]]\n","\n","  ...\n","\n","  [[163. 148. 145.]\n","   [164. 146. 144.]\n","   [164. 140. 138.]\n","   ...\n","   [145. 127. 115.]\n","   [140. 122. 110.]\n","   [139. 121. 109.]]\n","\n","  [[162. 146. 146.]\n","   [164. 146. 144.]\n","   [165. 141. 139.]\n","   ...\n","   [140. 122. 110.]\n","   [138. 120. 108.]\n","   [141. 123. 111.]]\n","\n","  [[161. 145. 145.]\n","   [163. 145. 143.]\n","   [166. 142. 142.]\n","   ...\n","   [137. 119. 107.]\n","   [136. 118. 106.]\n","   [143. 125. 113.]]]\n","\n","\n"," [[[ 46.  51.  57.]\n","   [ 51.  54.  59.]\n","   [ 77.  72.  76.]\n","   ...\n","   [117. 114. 109.]\n","   [121. 121. 119.]\n","   [121. 126. 122.]]\n","\n","  [[ 48.  53.  59.]\n","   [ 59.  60.  65.]\n","   [ 78.  73.  77.]\n","   ...\n","   [129. 124. 120.]\n","   [133. 134. 129.]\n","   [124. 129. 125.]]\n","\n","  [[ 53.  56.  61.]\n","   [ 61.  62.  66.]\n","   [ 70.  66.  67.]\n","   ...\n","   [130. 125. 121.]\n","   [134. 133. 129.]\n","   [121. 123. 118.]]\n","\n","  ...\n","\n","  [[193. 194. 189.]\n","   [192. 193. 188.]\n","   [188. 187. 182.]\n","   ...\n","   [ 57.  53.  54.]\n","   [ 77.  66.  72.]\n","   [120. 107. 114.]]\n","\n","  [[191. 193. 188.]\n","   [192. 193. 188.]\n","   [188. 187. 183.]\n","   ...\n","   [ 63.  59.  60.]\n","   [ 96.  85.  91.]\n","   [105.  92. 101.]]\n","\n","  [[191. 193. 188.]\n","   [189. 191. 186.]\n","   [185. 184. 180.]\n","   ...\n","   [ 78.  76.  77.]\n","   [121. 110. 116.]\n","   [100.  87.  96.]]]]\n"]}],"source":["# Making sure it's a 2D array\n","image_matrix = np.stack(df['image_array'].values)\n","print(image_matrix)"]},{"cell_type":"code","execution_count":null,"id":"0b07fdf8","metadata":{},"outputs":[],"source":["# It's a three dimensions array so we have to flatten it \n","image_matrix = np.array([img.flatten() for img in df['image_array']])\n","\n","# Scale the data\n","scaler = StandardScaler()\n","image_matrix_scaled = scaler.fit_transform(image_matrix)"]},{"cell_type":"code","execution_count":null,"id":"319d7906","metadata":{"execution":{"iopub.execute_input":"2024-05-10T18:09:49.276916Z","iopub.status.busy":"2024-05-10T18:09:49.276554Z"},"papermill":{"duration":0.020456,"end_time":"2024-05-09T20:23:09.245954","exception":false,"start_time":"2024-05-09T20:23:09.225498","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Start timing the overall process\n","start_time_overall = time.time()\n","\n","# Principal Component Analysis\n","pca_ratio=PCA()\n","pca_ratio.fit(image_matrix_scaled) # fit the PCA so it can learn\n","\n","# Using cumulative variance\n","cumulative_variance_ratio=np.cumsum(pca_ratio.explained_variance_ratio_)\n","variance=0.95 # set to 95% to keep a sufficiently large portion of the variance\n","n_components= np.argmax(cumulative_variance_ratio >= variance) +1 # find the number of components needed \n","\n","print(f\"Number of principal components: {n_components}\")\n","\n","# Calculate and print the overall running time\n","overall_time = time.time() - start_time_overall\n","print(f\"Total running time: {overall_time:.2f} seconds.\")\n","\n","# There is another way to obtain the number of components which is setting the threshold \n","# pca_threshold = PCA(n_components=0.95)\n","# pca_threshold.fit(image_matrix_scaled) - fit the pca model to the data to learn patterns\n","# print(f\"Number of principal components: {pca_threshold.n_components_}\")"]},{"cell_type":"code","execution_count":null,"id":"43f7ec86","metadata":{},"outputs":[],"source":["# Screen plot eigenvalues - number of principal components\n","plt.figure(figsize=(10, 6))\n","sns.lineplot(x=np.arange(1, len(cumulative_variance_ratio) + 1), y=cumulative_variance_ratio, marker='o', color='#FF69B4')\n","plt.title('Scree Plot')\n","plt.xlabel('Number of Components')\n","plt.ylabel('Cumulative Explained Variance Ratio')\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"e7db175a","metadata":{"papermill":{"duration":0.020219,"end_time":"2024-05-09T20:23:09.286611","exception":false,"start_time":"2024-05-09T20:23:09.266392","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Transform the original data using retained principal components \n","# Start from inputting in PCA the number of components found necessary for 95% variance\n","pca_opt=PCA(n_components=99)\n","pca_opt.fit(image_matrix_scaled)\n","\n","df_matrix_reduced= pca_opt.transform(image_matrix_scaled) # transform the flatten original data to reduced dimensionality"]},{"attachments":{},"cell_type":"markdown","id":"adb332d2","metadata":{},"source":["# SVM with PCA"]},{"cell_type":"code","execution_count":null,"id":"405a9932","metadata":{},"outputs":[],"source":["# Start timing the overall process\n","start_time_overall = time.time()\n","\n","# Split the Data in test and train\n","train_indices = df[df['subset'] == 'train'].index\n","test_indices = df[df['subset'] == 'test'].index\n","\n","X_train = df_matrix_reduced[train_indices]\n","X_test = df_matrix_reduced[test_indices]\n","y_train = df.loc[train_indices, 'category']\n","y_test = df.loc[test_indices, 'category']\n","\n","# Definition of the parameter grid for GridSearchCV\n","param_grid = {\n","    'C': [0.1, 1, 10, 100],\n","    'gamma': [0.0001, 0.001, 0.1, 1],\n","    'kernel': ['rbf', 'poly']\n","}\n","\n","# Creation of an SVC\n","svc = SVC(probability=True)\n","\n","# Creating the model using GridSearchCV with the parameter grid\n","model = GridSearchCV(svc, param_grid, cv=3, n_jobs=-1)\n","\n","# Training the model using training data\n","model.fit(X_train, y_train)\n","\n","# Print the best parameters\n","print(\"Best parameters found:\", model.best_params_)\n","\n","# Testing the model using test data\n","y_pred = model.predict(X_test)\n","\n","# Printing the classification report\n","print(classification_report(y_test, y_pred))\n","\n","# Calculate and print the overall running time\n","overall_time = time.time() - start_time_overall\n","print(f\"Total running time: {overall_time:.2f} seconds.\")"]},{"attachments":{},"cell_type":"markdown","id":"78259c1a","metadata":{},"source":["# SVM with PCA - sample of dataset"]},{"cell_type":"code","execution_count":null,"id":"de95630d","metadata":{},"outputs":[],"source":["# Start timing the overall process\n","start_time_overall = time.time()\n","\n","# Indices for training and testing data as defined in the 'subset' column\n","train_indices = df[df['subset'] == 'train'].index\n","test_indices = df[df['subset'] == 'test'].index\n","\n","# Randomly select 20% of the data from both training and testing subsets\n","train_indices_sample = train_test_split(train_indices, train_size=0.2, random_state=42)[0]\n","test_indices_sample = train_test_split(test_indices, test_size=0.2, random_state=42)[1]\n","\n","# Assign features and targets based on the selected indices\n","X_train = df_matrix_reduced[train_indices_sample]\n","X_test = df_matrix_reduced[test_indices_sample]\n","y_train = df.loc[train_indices_sample, 'category']\n","y_test = df.loc[test_indices_sample, 'category']\n","\n","# Import and configure the SVM model with GridSearchCV\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import GridSearchCV\n","\n","param_grid = {\n","    'C': [0.1, 1, 10, 100],\n","    'gamma': [0.0001, 0.001, 0.1, 1],\n","    'kernel': ['rbf', 'poly']\n","}\n","\n","svc = SVC(probability=True)\n","model = GridSearchCV(svc, param_grid, cv=5, n_jobs=-1)\n","model.fit(X_train, y_train)\n","\n","# Print the best parameters\n","print(\"Best parameters found:\", model.best_params_)\n","\n","# Testing the model using test data\n","y_pred = model.predict(X_test)\n","\n","# Printing the classification report\n","print(classification_report(y_test, y_pred))\n","\n","# Calculate and print the overall running time\n","overall_time = time.time() - start_time_overall\n","print(f\"Total running time: {overall_time:.2f} seconds.\")"]},{"attachments":{},"cell_type":"markdown","id":"2023d7ca","metadata":{},"source":["# SVM without PCA - sample of dataset"]},{"cell_type":"code","execution_count":null,"id":"e9d5402a","metadata":{},"outputs":[],"source":["# Start timing the overall process\n","start_time_overall = time.time()\n","\n","# Indices for training and testing data as defined in the 'subset' column\n","train_indices = df[df['subset'] == 'train'].index\n","test_indices = df[df['subset'] == 'test'].index\n","\n","# Randomly select 20% of the data from both training and testing subsets\n","train_indices_sample = train_test_split(train_indices, train_size=0.2, random_state=42)[0]\n","test_indices_sample = train_test_split(test_indices, test_size=0.2, random_state=42)[1]\n","\n","# Assign features and targets based on the selected indices\n","X_train = image_matrix_scaled[train_indices_sample]\n","X_test = image_matrix_scaled[test_indices_sample]\n","y_train = df.loc[train_indices_sample, 'category']\n","y_test = df.loc[test_indices_sample, 'category']\n","\n","# Import and configure the SVM model with GridSearchCV\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import GridSearchCV\n","\n","param_grid = {\n","    'C': [0.1, 1, 10, 100],\n","    'gamma': [0.0001, 0.001, 0.1, 1],\n","    'kernel': ['rbf', 'poly']\n","}\n","\n","svc = SVC(probability=True)\n","model = GridSearchCV(svc, param_grid, cv=3, n_jobs=-1)\n","model.fit(X_train, y_train)\n","\n","# Divide test data into 4 batches for classification\n","batch_size = len(X_test) // 4  # Calculate the batch size based on the total number of samples in the test set\n","\n","for i in range(4):\n","    start_index = i * batch_size\n","    end_index = start_index + batch_size if i < 3 else len(X_test)  # Ensure the last batch includes all remaining data\n","\n","    X_batch = X_test[start_index:end_index]\n","    y_batch = y_test[start_index:end_index]\n","    \n","    # Predict model on the batch\n","    y_pred_batch = model.predict(X_batch)\n","    \n","    # Print the classification report for the current batch\n","    print(f\"Classification Report for Batch {i+1}\")\n","    print(classification_report(y_batch, y_pred_batch))\n","    print(\"\\n\" + \"-\"*80 + \"\\n\")\n","\n","# Calculate and print the overall running time\n","overall_time = time.time() - start_time_overall\n","print(f\"Total running time: {overall_time:.2f} seconds.\")"]},{"attachments":{},"cell_type":"markdown","id":"2c50f349","metadata":{},"source":["# SVM with PCA with SGDClassifier "]},{"cell_type":"code","execution_count":null,"id":"0614d943","metadata":{},"outputs":[],"source":["# Start timing the overall process\n","start_time_overall = time.time()\n","\n","# SVM without PCA\n","X_train = df_matrix_reduced[df['subset'] == 'train']\n","y_train = df[df['subset'] == 'train']['category']\n","X_test = df_matrix_reduced[df['subset'] == 'test']\n","y_test = df[df['subset'] == 'test']['category']\n","\n","# Define parameter grid for SGDClassifier\n","param_grid_sgd = {\n","    'alpha': [0.0001, 0.001, 0.01, 0.1],  # Regularization parameter\n","    'penalty': ['l2', 'l1', 'elasticnet'],\n","    'loss': ['hinge']  # Hinge loss corresponds to a linear SVM\n","}\n","\n","# Create SGDClassifier\n","sgd = SGDClassifier(max_iter=1000, tol=1e-3)\n","\n","# Create GridSearchCV model\n","grid_search_sgd = GridSearchCV(sgd, param_grid_sgd, cv=3, n_jobs=-1)\n","\n","# Train model using training data\n","grid_search_sgd.fit(X_train, y_train)\n","\n","# Print the best parameters\n","print(\"Best parameters found:\", grid_search_sgd.best_params_)\n","\n","# Test model using test data\n","y_pred_sgd = grid_search_sgd.predict(X_test)\n","\n","# Print classification report\n","print(classification_report(y_test,y_pred_sgd))\n","\n","# Calculate and print the overall running time\n","overall_time = time.time() - start_time_overall\n","print(f\"Total running time: {overall_time:.2f} seconds.\")"]},{"attachments":{},"cell_type":"markdown","id":"90070fe2","metadata":{},"source":["# SVM without PCA with SGDClassifier- sample of dataset"]},{"cell_type":"code","execution_count":null,"id":"e9ea2e05","metadata":{},"outputs":[],"source":["# Start timing the overall process\n","start_time_overall = time.time()\n","\n","# Indices for training and testing data as defined in the 'subset' column\n","train_indices = df[df['subset'] == 'train'].index\n","test_indices = df[df['subset'] == 'test'].index\n","\n","# Randomly select 20% of the data from both training and testing subsets\n","train_indices_sample = train_test_split(train_indices, train_size=0.2, random_state=42)[0]\n","test_indices_sample = train_test_split(test_indices, test_size=0.2, random_state=42)[1]\n","\n","# Assign features and targets based on the selected indices\n","X_train = image_matrix_scaled[train_indices_sample]\n","X_test = image_matrix_scaled[test_indices_sample]\n","y_train = df.loc[train_indices_sample, 'category']\n","y_test = df.loc[test_indices_sample, 'category']\n","\n","# Define parameter grid for SGDClassifier\n","param_grid_sgd = {\n","    'alpha': [0.0001, 0.001, 0.01, 0.1],  # Regularization parameter\n","    'penalty': ['l2', 'l1', 'elasticnet'],\n","    'loss': ['hinge']  # Hinge loss corresponds to a linear SVM\n","}\n","\n","# Create SGDClassifier\n","sgd = SGDClassifier(max_iter=1000, tol=1e-3)\n","\n","# Create GridSearchCV model\n","grid_search_sgd = GridSearchCV(sgd, param_grid_sgd, cv=3, n_jobs=-1)\n","\n","# Train model using training data\n","grid_search_sgd.fit(X_train, y_train)\n","\n","# Print the best parameters\n","print(\"Best parameters found:\", grid_search_sgd.best_params_)\n","\n","# Divide test data into 4 batches for classification\n","batch_size = len(X_test) // 4  # Calculate the batch size based on the total number of samples in the test set\n","\n","for i in range(4):\n","    start_index = i * batch_size\n","    end_index = start_index + batch_size if i < 3 else len(X_test)  # Ensure the last batch includes all remaining data\n","\n","    X_batch = X_test[start_index:end_index]\n","    y_batch = y_test[start_index:end_index]\n","    \n","    # Predict model on the batch\n","    y_pred_batch = grid_search_sgd.predict(X_batch)\n","    \n","    # Print the classification report for the current batch\n","    print(f\"Classification Report for Batch {i+1}\")\n","    print(classification_report(y_batch, y_pred_batch))\n","    print(\"\\n\" + \"-\"*80 + \"\\n\")\n","\n","# Calculate and print the overall running time\n","overall_time = time.time() - start_time_overall\n","print(f\"Total running time: {overall_time:.2f} seconds.\")\n"]},{"attachments":{},"cell_type":"markdown","id":"84e3a8aa","metadata":{},"source":["# SVM with PCA with SGDClassifier - sample of a dataset"]},{"cell_type":"code","execution_count":null,"id":"5c590290","metadata":{},"outputs":[],"source":["# Start timing the overall process\n","start_time_overall = time.time()\n","\n","# Indices for training and testing data as defined in the 'subset' column\n","train_indices = df[df['subset'] == 'train'].index\n","test_indices = df[df['subset'] == 'test'].index\n","\n","# Randomly select 20% of the data from both training and testing subsets\n","train_indices_sample = train_test_split(train_indices, train_size=0.2, random_state=42)[0]\n","test_indices_sample = train_test_split(test_indices, test_size=0.2, random_state=42)[1]\n","\n","# Assign features and targets based on the selected indices\n","X_train = df_matrix_reduced[train_indices_sample]\n","X_test = df_matrix_reduced[test_indices_sample]\n","y_train = df.loc[train_indices_sample, 'category']\n","y_test = df.loc[test_indices_sample, 'category']\n","\n","# Define parameter grid for SGDClassifier\n","param_grid_sgd = {\n","    'alpha': [0.0001, 0.001, 0.01, 0.1],  # Regularization parameter\n","    'penalty': ['l2', 'l1', 'elasticnet'],\n","    'loss': ['hinge']  # Hinge loss corresponds to a linear SVM\n","}\n","\n","# Create SGDClassifier\n","sgd = SGDClassifier(max_iter=1000, tol=1e-3)\n","\n","# Create GridSearchCV model\n","grid_search_sgd = GridSearchCV(sgd, param_grid_sgd, cv=3, n_jobs=-1)\n","\n","# Train model using training data\n","grid_search_sgd.fit(X_train, y_train)\n","\n","# Print the best parameters\n","print(\"Best parameters found:\", grid_search_sgd.best_params_)\n","\n","# Divide test data into 4 batches for classification\n","batch_size = len(X_test) // 4  # Calculate the batch size based on the total number of samples in the test set\n","\n","for i in range(4):\n","    start_index = i * batch_size\n","    end_index = start_index + batch_size if i < 3 else len(X_test)  # Ensure the last batch includes all remaining data\n","\n","    X_batch = X_test[start_index:end_index]\n","    y_batch = y_test[start_index:end_index]\n","    \n","    # Predict model on the batch\n","    y_pred_batch = grid_search_sgd.predict(X_batch)\n","    \n","    # Print the classification report for the current batch\n","    print(f\"Classification Report for Batch {i+1}\")\n","    print(classification_report(y_batch, y_pred_batch))\n","    print(\"\\n\" + \"-\"*80 + \"\\n\")\n","\n","# Calculate and print the overall running time\n","overall_time = time.time() - start_time_overall\n","print(f\"Total running time: {overall_time:.2f} seconds.\")"]},{"attachments":{},"cell_type":"markdown","id":"85028cc2","metadata":{},"source":["# Visualising the results of SVM"]},{"cell_type":"code","execution_count":null,"id":"754f9f3e","metadata":{},"outputs":[],"source":["# Confusion Matrix\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n","plt.xlabel('Predicted')\n","plt.ylabel('Actual')\n","plt.title('Confusion Matrix')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"4a685611","metadata":{},"outputs":[],"source":["# Model instantiation\n","modelSVC = SVC()\n","\n","# Set train_sizes values to start with a larger subset to ensure each split has sufficient data\n","train_sizes = np.linspace(0.4, 1.0, 5)  # Start at 40% to avoid too small training sets\n","\n","# Use stratified cross-validation\n","cv = StratifiedKFold(n_splits=3)\n","\n","# Compute learning curve\n","try:\n","    train_sizes, train_scores, val_scores = learning_curve(\n","        modelSVC, X_train, y_train, cv=3, n_jobs=-1, train_sizes=train_sizes, error_score='raise'\n","    )\n","except ValueError as e:\n","    print(\"Error occurred during learning curve computation:\")\n","    print(e)\n","\n","# Compute mean scores if learning curve computation is successful\n","if 'train_sizes' in locals() and 'train_scores' in locals() and 'val_scores' in locals():\n","    train_scores_mean = np.mean(train_scores, axis=1)\n","    val_scores_mean = np.mean(val_scores, axis=1)\n","\n","    # Plot learning curve\n","    plt.figure(figsize=(8, 6))\n","    plt.plot(train_sizes, train_scores_mean, label='Training score')\n","    plt.plot(train_sizes, val_scores_mean, label='Cross-validation score')\n","    plt.xlabel('Training examples')\n","    plt.ylabel('Score')\n","    plt.title('Learning Curves')\n","    plt.legend(loc='best')\n","    plt.show()\n","else:\n","    print(\"Learning curve computation failed due to insufficient class representation in some splits.\")"]},{"attachments":{},"cell_type":"markdown","id":"49c787cd","metadata":{},"source":["# CNN - TF & Keras (Version 1)"]},{"attachments":{},"cell_type":"markdown","id":"0e9160ba","metadata":{},"source":["LOAD Dataset"]},{"cell_type":"code","execution_count":null,"id":"594d696f","metadata":{},"outputs":[],"source":["df['category_encoded'] = df['category'].apply(lambda x: to_categorical(x, num_classes=3))\n"]},{"attachments":{},"cell_type":"markdown","id":"86c00215","metadata":{},"source":["Split the data into training, validation, and test sets"]},{"cell_type":"code","execution_count":null,"id":"c02a49a4","metadata":{},"outputs":[],"source":["train_df, test_df = train_test_split(df[df['subset'] == 'train'], test_size=0.2, random_state=42)\n","train_df, val_df = train_test_split(train_df, test_size=0.25, random_state=42)  # This will make 60% train, 20% validation\n"]},{"attachments":{},"cell_type":"markdown","id":"5ab26af4","metadata":{},"source":["Function to convert DataFrame to tf.data.Dataset with optional augmentation"]},{"cell_type":"code","execution_count":null,"id":"14f1e222","metadata":{},"outputs":[],"source":["def df_to_dataset(dataframe, shuffle=True, batch_size=32, augment=False):\n","    images = np.stack(dataframe['image_array'].values)\n","    labels = np.stack(dataframe['category_encoded'].values)\n","    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n","    \n","    if shuffle:\n","        dataset = dataset.shuffle(buffer_size=len(dataframe))\n","    \n","    if augment:\n","        dataset = dataset.map(lambda img, lbl: (tf.image.random_flip_left_right(img), lbl),\n","                              num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","    \n","    dataset = dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n","    return dataset"]},{"attachments":{},"cell_type":"markdown","id":"d5169094","metadata":{},"source":["Create TensorFlow datasets"]},{"cell_type":"code","execution_count":null,"id":"ef1da362","metadata":{},"outputs":[],"source":["train_ds = df_to_dataset(train_df, shuffle=True, batch_size=32, augment=True)\n","val_ds = df_to_dataset(val_df, batch_size=32, shuffle=False)\n","test_ds = df_to_dataset(test_df, batch_size=32, shuffle=False)\n"]},{"attachments":{},"cell_type":"markdown","id":"585b52f9","metadata":{},"source":["Define the CNN model "]},{"cell_type":"code","execution_count":null,"id":"843e146c","metadata":{},"outputs":[],"source":["model = Sequential([\n","    Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)),\n","    MaxPooling2D(2, 2),\n","    BatchNormalization(),\n","\n","    Conv2D(64, (3,3), activation='relu'),\n","    MaxPooling2D(2,2),\n","    BatchNormalization(),\n","    \n","    Conv2D(128, (3,3), activation='relu'),\n","    MaxPooling2D(2,2),\n","    BatchNormalization(),\n","\n","    Flatten(),\n","    Dense(512, activation='relu'),\n","    Dropout(0.5),\n","    Dense(3, activation='softmax')\n","])"]},{"cell_type":"code","execution_count":null,"id":"2794c90b","metadata":{},"outputs":[],"source":["model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","print(model.summary())"]},{"attachments":{},"cell_type":"markdown","id":"2e8a648c","metadata":{},"source":["Train the model"]},{"attachments":{},"cell_type":"markdown","id":"3f8d7e46","metadata":{},"source":["history = model.fit(\n","    train_ds,\n","    epochs=20,\n","    validation_data=val_ds\n",")"]},{"attachments":{},"cell_type":"markdown","id":"68d85c60","metadata":{},"source":["Evaluate the model on the test dataset"]},{"cell_type":"code","execution_count":null,"id":"d2307d20","metadata":{},"outputs":[],"source":["test_loss, test_accuracy = model.evaluate(test_ds)\n","print(\"Test Accuracy:\", test_accuracy)"]},{"attachments":{},"cell_type":"markdown","id":"a9e9114c","metadata":{},"source":["Plot training and validation accuracy and loss"]},{"cell_type":"code","execution_count":null,"id":"7e09d0e7","metadata":{},"outputs":[],"source":["plt.figure(figsize=(12, 5))\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['accuracy'], label='Training Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.title('Training and Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","id":"743c42a6","metadata":{},"source":["Classification Report and Confusion Matrix"]},{"cell_type":"code","execution_count":null,"id":"f81700b9","metadata":{},"outputs":[],"source":["# Predict the labels on the test dataset\n","test_images, test_labels = next(iter(test_ds.unbatch().batch(len(test_df))))\n","predicted_probs = model.predict(test_images)\n","predicted_labels = np.argmax(predicted_probs, axis=1)\n","true_labels = np.argmax(test_labels, axis=1)\n","\n","# Generate the classification report\n","class_report = classification_report(true_labels, predicted_labels, target_names=['Class 0', 'Class 1', 'Class 2'])\n","print(\"Classification Report:\")\n","print(class_report)\n","\n","# Generate the confusion matrix\n","conf_matrix = confusion_matrix(true_labels, predicted_labels)\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)\n","\n","# Plotting the confusion matrix\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1', 'Class 2'], yticklabels=['Class 0', 'Class 1', 'Class 2'])\n","plt.xlabel('Predicted Labels')\n","plt.ylabel('True Labels')\n","plt.title('Confusion Matrix')\n","plt.show()\n"]},{"attachments":{},"cell_type":"markdown","id":"1990dd0b","metadata":{},"source":["# CNN  - TF&Keras (Version 2)"]},{"attachments":{},"cell_type":"markdown","id":"5b8c25c7","metadata":{},"source":["Load Dataset"]},{"cell_type":"code","execution_count":null,"id":"b760d67f","metadata":{},"outputs":[],"source":["df['category_encoded'] = df['category'].apply(lambda x: to_categorical(x, num_classes=3))"]},{"attachments":{},"cell_type":"markdown","id":"f70c91d7","metadata":{},"source":["Split the data into training, validation, and test sets"]},{"cell_type":"code","execution_count":null,"id":"9edb0ed5","metadata":{},"outputs":[],"source":["train_df, test_df = train_test_split(df[df['subset'] == 'train'], test_size=0.2, random_state=42)\n","train_df, val_df = train_test_split(train_df, test_size=0.25, random_state=42)  # This will make 60% train, 20% validation"]},{"attachments":{},"cell_type":"markdown","id":"f29d8c48","metadata":{},"source":["Function to convert DataFrame to tf.data.Dataset with optional augmentation"]},{"cell_type":"code","execution_count":null,"id":"71d38270","metadata":{},"outputs":[],"source":["def df_to_dataset(dataframe, shuffle=True, batch_size=32, augment=False):\n","    images = np.stack(dataframe['image_array'].values)\n","    labels = np.stack(dataframe['category_encoded'].values)\n","    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n","    \n","    if shuffle:\n","        dataset = dataset.shuffle(buffer_size=len(dataframe))\n","    \n","    if augment:\n","        dataset = dataset.map(lambda img, lbl: (tf.image.random_flip_left_right(img), lbl),\n","                              num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","    \n","    dataset = dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n","    return dataset"]},{"attachments":{},"cell_type":"markdown","id":"4c300c28","metadata":{},"source":["Create TensorFlow Datasets"]},{"cell_type":"code","execution_count":null,"id":"fbe1851c","metadata":{},"outputs":[],"source":["train_ds = df_to_dataset(train_df, shuffle=True, batch_size=32, augment=True)\n","val_ds = df_to_dataset(val_df, batch_size=32, shuffle=False)\n","test_ds = df_to_dataset(test_df, batch_size=32, shuffle=False)\n"]},{"attachments":{},"cell_type":"markdown","id":"7cbffe33","metadata":{},"source":["Define the Model Building Function"]},{"cell_type":"code","execution_count":null,"id":"6efb147a","metadata":{},"outputs":[],"source":["def build_model(hp):\n","    model = Sequential()\n","    model.add(Conv2D(filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=32),\n","                     kernel_size=hp.Choice('conv_1_kernel', values=[3,5]),\n","                     activation='relu',\n","                     input_shape=(128, 128, 3)))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling2D(2, 2))\n","\n","    for i in range(hp.Int('n_layers', 1, 3)):\n","        model.add(Conv2D(filters=hp.Int(f'conv_{i+2}_filter', min_value=32, max_value=128, step=32),\n","                         kernel_size=hp.Choice(f'conv_{i+2}_kernel', values=[3,5]),\n","                         activation='relu'))\n","        model.add(BatchNormalization())\n","        model.add(MaxPooling2D(2, 2))\n","\n","    model.add(Flatten())\n","    model.add(Dense(units=hp.Int('dense_units', min_value=512, max_value=1024, step=256),\n","                    activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(3, activation='softmax'))\n","    \n","    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","    return model"]},{"attachments":{},"cell_type":"markdown","id":"af268f41","metadata":{},"source":["Set Up the Hyperparameter Search"]},{"cell_type":"code","execution_count":null,"id":"547d4c64","metadata":{},"outputs":[],"source":["tuner = RandomSearch(\n","    build_model,\n","    objective='val_accuracy',\n","    max_trials=10,  # Number of variations on model\n","    executions_per_trial=1,  # Number of models that should be built and fit for each trial\n","    directory='output',\n","    project_name='ModelTuning'\n",")\n","\n","# Display search space summary\n","tuner.search_space_summary()"]},{"attachments":{},"cell_type":"markdown","id":"84a1deed","metadata":{},"source":["Start the Hyperparameter Tuning"]},{"cell_type":"code","execution_count":null,"id":"d3fe863d","metadata":{},"outputs":[],"source":["tuner.search(train_ds, epochs=10, validation_data=val_ds)"]},{"attachments":{},"cell_type":"markdown","id":"d7703edd","metadata":{},"source":["Get the Best Model"]},{"cell_type":"code","execution_count":null,"id":"17884018","metadata":{},"outputs":[],"source":["best_model = tuner.get_best_models(num_models=1)[0]\n","best_model.summary()\n"]},{"attachments":{},"cell_type":"markdown","id":"571ea806","metadata":{},"source":["Evaluate the best model"]},{"cell_type":"code","execution_count":null,"id":"c5aad95f","metadata":{},"outputs":[],"source":["best_model = tuner.get_best_models(num_models=1)[0]\n","best_model.summary()"]},{"attachments":{},"cell_type":"markdown","id":"21eb49d8","metadata":{},"source":["Predict and Report"]},{"cell_type":"code","execution_count":null,"id":"26ab6c19","metadata":{},"outputs":[],"source":["test_images, test_labels = next(iter(test_ds.unbatch().batch(len(test_df))))\n","predicted_probs = best_model.predict(test_images)\n","predicted_labels = np.argmax(predicted_probs, axis=1)\n","true_labels = np.argmax(test_labels, axis=1)\n","\n","from sklearn.metrics import classification_report, confusion_matrix\n","print(\"Classification Report:\")\n","print(classification_report(true_labels, predicted_labels, target_names=['Class 0', 'Class 1', 'Class 2']))\n","\n","print(\"Confusion Matrix:\")\n","print(confusion_matrix(true_labels, predicted_labels))\n"]},{"cell_type":"code","execution_count":null,"id":"7ef5eedf","metadata":{},"outputs":[],"source":["# Running time histogram"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30698,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"papermill":{"default_parameters":{},"duration":69.191232,"end_time":"2024-05-09T20:23:11.684837","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-05-09T20:22:02.493605","version":"2.5.0"}},"nbformat":4,"nbformat_minor":5}
