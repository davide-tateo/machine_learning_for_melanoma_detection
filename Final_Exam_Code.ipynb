{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"papermill":{"duration":0.004634,"end_time":"2024-05-09T20:22:05.309483","exception":false,"start_time":"2024-05-09T20:22:05.304849","status":"completed"},"tags":[]},"source":["## Final Exam Machine Learning"]},{"attachments":{},"cell_type":"markdown","id":"26d770b5","metadata":{"papermill":{"duration":0.003633,"end_time":"2024-05-09T20:22:05.317362","exception":false,"start_time":"2024-05-09T20:22:05.313729","status":"completed"},"tags":[]},"source":["Davide Tateo; 167275\n","\n","Francesca Salute; 167284\n","\n","Nicole Favero; 167340 \n","\n","Tomás Gonçalves; 167288"]},{"cell_type":"code","execution_count":2,"id":"c01b779b","metadata":{"execution":{"iopub.execute_input":"2024-05-10T18:08:40.949064Z","iopub.status.busy":"2024-05-10T18:08:40.948741Z","iopub.status.idle":"2024-05-10T18:09:09.501056Z","shell.execute_reply":"2024-05-10T18:09:09.499950Z","shell.execute_reply.started":"2024-05-10T18:08:40.949036Z"},"papermill":{"duration":25.36528,"end_time":"2024-05-09T20:22:30.686398","exception":false,"start_time":"2024-05-09T20:22:05.321118","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["#!git clone https://github.com/frasalute/ML_FinalExam.git"]},{"cell_type":"code","execution_count":3,"id":"7a3b910d","metadata":{"execution":{"iopub.execute_input":"2024-05-10T18:09:09.503406Z","iopub.status.busy":"2024-05-10T18:09:09.503084Z","iopub.status.idle":"2024-05-10T18:09:09.509111Z","shell.execute_reply":"2024-05-10T18:09:09.508194Z","shell.execute_reply.started":"2024-05-10T18:09:09.503378Z"},"papermill":{"duration":0.02752,"end_time":"2024-05-09T20:22:30.733003","exception":false,"start_time":"2024-05-09T20:22:30.705483","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Current working directory: c:\\Users\\davit\\Desktop\\CBS\\MACHINE LEARNING\\GithubExam\\ML_FinalExam\n","Contents of the current directory: ['.DS_Store', '.git', 'Final_Exam_Code.ipynb', 'images', 'LICENSE', 'README.md']\n"]}],"source":["import os\n","print(f\"Current working directory: {os.getcwd()}\")\n","print(f\"Contents of the current directory: {os.listdir('.')}\")"]},{"cell_type":"code","execution_count":4,"id":"16362855","metadata":{"execution":{"iopub.execute_input":"2024-05-10T18:09:09.510546Z","iopub.status.busy":"2024-05-10T18:09:09.510247Z","iopub.status.idle":"2024-05-10T18:09:09.519289Z","shell.execute_reply":"2024-05-10T18:09:09.518454Z","shell.execute_reply.started":"2024-05-10T18:09:09.510523Z"},"papermill":{"duration":0.037028,"end_time":"2024-05-09T20:22:30.788959","exception":false,"start_time":"2024-05-09T20:22:30.751931","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Base path is: /work/ML_FinalExam/images\n"]}],"source":["base_path = '/work/ML_FinalExam/images'\n","print(\"Base path is:\", base_path)"]},{"cell_type":"code","execution_count":5,"id":"663cd4c7","metadata":{},"outputs":[],"source":["# pip install tensorflow\n","# pip install scikit-learn\n","# pip install seaborn"]},{"cell_type":"code","execution_count":7,"id":"c40083af","metadata":{"execution":{"iopub.execute_input":"2024-05-10T18:09:09.521490Z","iopub.status.busy":"2024-05-10T18:09:09.521163Z","iopub.status.idle":"2024-05-10T18:09:20.959571Z","shell.execute_reply":"2024-05-10T18:09:20.958687Z","shell.execute_reply.started":"2024-05-10T18:09:09.521449Z"},"papermill":{"duration":13.163557,"end_time":"2024-05-09T20:22:43.976467","exception":false,"start_time":"2024-05-09T20:22:30.812910","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        # Currently, memory growth needs to be the same across GPUs\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","    except RuntimeError as e:\n","        # Memory growth must be set before GPUs have been initialized\n","        print(e)"]},{"cell_type":"code","execution_count":8,"id":"8ada059f","metadata":{"execution":{"iopub.execute_input":"2024-05-10T18:09:20.961275Z","iopub.status.busy":"2024-05-10T18:09:20.960741Z","iopub.status.idle":"2024-05-10T18:09:20.969758Z","shell.execute_reply":"2024-05-10T18:09:20.968699Z","shell.execute_reply.started":"2024-05-10T18:09:20.961247Z"},"papermill":{"duration":0.030045,"end_time":"2024-05-09T20:22:44.024258","exception":false,"start_time":"2024-05-09T20:22:43.994213","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Importing required API and modules\n","import warnings\n","import numpy as np\n","import pandas as pd\n","from tensorflow.keras.utils import img_to_array\n","from keras.preprocessing.image import array_to_img\n","from tensorflow.keras.utils import load_img\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":null,"id":"9f3f07cf","metadata":{"execution":{"iopub.execute_input":"2024-05-10T18:09:20.971501Z","iopub.status.busy":"2024-05-10T18:09:20.971183Z","iopub.status.idle":"2024-05-10T18:09:37.961718Z","shell.execute_reply":"2024-05-10T18:09:37.960866Z","shell.execute_reply.started":"2024-05-10T18:09:20.971472Z"},"papermill":{"duration":16.952118,"end_time":"2024-05-09T20:23:00.994037","exception":false,"start_time":"2024-05-09T20:22:44.041919","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def load_and_resize_images(base_path, categories, target_size=(64, 64)):  # changed size from 128 to 64 to make it faster\n","    data = {'photo_id': [], 'image': [], 'image_array': [], 'category': [], 'subset': []}\n","    \n","    for subset in ['train', 'test']:\n","        for category in categories.keys():\n","            folder_path = os.path.join(base_path, subset, category)\n","            for filename in os.listdir(folder_path):\n","                if filename.lower().endswith(('.jpg', '.jpeg')):  # Check for both .jpg and .jpeg extensions\n","                    file_path = os.path.join(folder_path, filename)\n","                    # Load and resize the image\n","                    image = load_img(file_path, target_size=target_size)\n","                    image_array = img_to_array(image)\n","                    # Add data to the DataFrame\n","                    data['photo_id'].append(filename)\n","                    data['image'].append(image)\n","                    data['image_array'].append(image_array)\n","                    data['category'].append(categories[category])\n","                    data['subset'].append(subset)\n","    \n","    df = pd.DataFrame(data)\n","    return df\n","\n","# Load the DataFrame\n","categories = {'Benign': 0, 'Malignant': 1, 'Undetected': 2}\n","base_path = '/work/ML_FinalExam/images'\n","df = load_and_resize_images(base_path,categories)"]},{"cell_type":"code","execution_count":null,"id":"527f6db1","metadata":{"execution":{"iopub.execute_input":"2024-05-10T18:09:37.963115Z","iopub.status.busy":"2024-05-10T18:09:37.962823Z","iopub.status.idle":"2024-05-10T18:09:45.968376Z","shell.execute_reply":"2024-05-10T18:09:45.967399Z","shell.execute_reply.started":"2024-05-10T18:09:37.963091Z"},"papermill":{"duration":8.100521,"end_time":"2024-05-09T20:23:09.114178","exception":false,"start_time":"2024-05-09T20:23:01.013657","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["   photo_id                                              image  \\\n","0  6154.jpg  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n","1  3582.jpg  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n","2  2657.jpg  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n","3     2.jpg  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n","4  4941.jpg  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n","\n","                                         image_array  category  \n","0  [[[170.0, 129.0, 145.0], [172.0, 131.0, 147.0]...         0  \n","1  [[[140.0, 108.0, 87.0], [141.0, 109.0, 88.0], ...         0  \n","2  [[[170.0, 130.0, 156.0], [174.0, 134.0, 160.0]...         0  \n","3  [[[253.0, 202.0, 245.0], [255.0, 205.0, 248.0]...         0  \n","4  [[[182.0, 144.0, 155.0], [183.0, 145.0, 156.0]...         0  \n","Number of rows in the DataFrame: 13879\n"]}],"source":["print(df.head())\n","row_count = len(df)\n","print(\"Number of rows in the DataFrame:\", row_count)"]},{"attachments":{},"cell_type":"markdown","id":"401082fc","metadata":{"papermill":{"duration":0.016977,"end_time":"2024-05-09T20:23:09.148992","exception":false,"start_time":"2024-05-09T20:23:09.132015","status":"completed"},"tags":[]},"source":["# Augmentation of \"undetected\" datasets"]},{"cell_type":"code","execution_count":11,"id":"f3edf820","metadata":{"execution":{"iopub.execute_input":"2024-05-10T18:09:45.970020Z","iopub.status.busy":"2024-05-10T18:09:45.969685Z","iopub.status.idle":"2024-05-10T18:09:45.980497Z","shell.execute_reply":"2024-05-10T18:09:45.979563Z","shell.execute_reply.started":"2024-05-10T18:09:45.969993Z"},"papermill":{"duration":0.035787,"end_time":"2024-05-09T20:23:09.204724","exception":false,"start_time":"2024-05-09T20:23:09.168937","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["\n","# Set the source directory and the target directories\n","original_undetected_dir = './images/undetec_to_augm'\n","train_augm_undetected_dir = './images/train/Undetected'\n","test_augm_undetected_dir ='./images/test/Undetected'\n","\n","# Create a data generator for augmentation\n","datagen = ImageDataGenerator(\n","    rotation_range=30,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    brightness_range = [0.8, 1.3],\n","    fill_mode='nearest'\n",")\n","\n","def augment_img_dataset(source_dir, target_dir, target_count, imagedata_generator):\n","\n","    \"\"\"\n","        #this function performs augmentation\n","\n","        # source_dir:           directory containing the original dataset to augment\n","        # target_dir:           directory where to save the augmented images\n","        # target_count:         desired number of images after augmentation\n","        # imagedata_generator:  image data generator object to be used for aumentation\n","\n","        # returns:              augmented set of images\n","    \"\"\" \n","\n","    # List the files in the source directory containing the original dataset \n","    file_list = os.listdir(source_dir)\n","    # Number of images in the original dataset\n","    original_count = len(file_list)\n","\n","    # Number of times to repeat each image to reach the target count\n","    repeats_1 = min(target_count // original_count + 1, len(file_list))\n","\n","    # Ensure the target directories exist\n","    os.makedirs(target_dir, exist_ok=True)    \n","\n","    # Augment and save the images for the 6000 train images\n","    for file in file_list:\n","        img_path = os.path.join(source_dir, file)\n","        img = load_img(img_path)\n","        img = img_to_array(img)\n","        img = img.reshape((1,) + img.shape)\n","\n","        i = 0\n","        for batch in imagedata_generator.flow(img, batch_size=1, save_to_dir = target_dir, save_prefix='augm', save_format='jpeg'): \n","            #if in the previous line i save them as jpg, it anyway augments only the jpeg ones\n","            i += 1\n","            if i >= repeats_1:\n","                break  # break the loop after reaching the desired number of augmented images\n","\n","\n","\n","#hhi \n","### AVOID RUNNING THE FOLLOWING IF DATASET HAS ALREADY BEEN AUGMENTED ###\n","            \n","# Perform augmentation to expand the train and test datasets for \"undetected\"\n","    #augment_img_dataset(original_undetected_dir, train_augm_undetected_dir, 6000, datagen)\n","    #augment_img_dataset(original_undetected_dir, test_augm_undetected_dir, 1000, datagen)\n"]},{"cell_type":"code","execution_count":10,"id":"06ceba23","metadata":{"execution":{"iopub.execute_input":"2024-05-10T18:09:45.995871Z","iopub.status.busy":"2024-05-10T18:09:45.995568Z","iopub.status.idle":"2024-05-10T18:09:46.846707Z","shell.execute_reply":"2024-05-10T18:09:46.845757Z","shell.execute_reply.started":"2024-05-10T18:09:45.995848Z"},"trusted":true},"outputs":[],"source":["from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","execution_count":11,"id":"916d5035","metadata":{"execution":{"iopub.execute_input":"2024-05-10T18:09:46.848363Z","iopub.status.busy":"2024-05-10T18:09:46.847987Z","iopub.status.idle":"2024-05-10T18:09:49.275234Z","shell.execute_reply":"2024-05-10T18:09:49.274327Z","shell.execute_reply.started":"2024-05-10T18:09:46.848332Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[[170. 129. 145.]\n","   [172. 131. 147.]\n","   [170. 129. 145.]\n","   ...\n","   [202. 167. 174.]\n","   [200. 165. 172.]\n","   [199. 164. 171.]]\n","\n","  [[169. 128. 144.]\n","   [171. 130. 146.]\n","   [172. 131. 147.]\n","   ...\n","   [202. 167. 174.]\n","   [200. 165. 172.]\n","   [199. 164. 171.]]\n","\n","  [[170. 129. 145.]\n","   [171. 130. 146.]\n","   [173. 132. 146.]\n","   ...\n","   [202. 167. 174.]\n","   [201. 166. 173.]\n","   [199. 164. 171.]]\n","\n","  ...\n","\n","  [[176. 144. 149.]\n","   [179. 147. 152.]\n","   [183. 148. 154.]\n","   ...\n","   [195. 159. 163.]\n","   [193. 157. 161.]\n","   [191. 155. 159.]]\n","\n","  [[174. 142. 147.]\n","   [177. 145. 150.]\n","   [182. 147. 153.]\n","   ...\n","   [196. 160. 164.]\n","   [193. 157. 161.]\n","   [191. 155. 159.]]\n","\n","  [[173. 141. 146.]\n","   [176. 144. 149.]\n","   [181. 146. 152.]\n","   ...\n","   [195. 159. 163.]\n","   [193. 157. 161.]\n","   [190. 154. 158.]]]\n","\n","\n"," [[[140. 108.  87.]\n","   [141. 109.  88.]\n","   [143. 111.  90.]\n","   ...\n","   [133. 100.  85.]\n","   [147. 114.  99.]\n","   [137. 104.  89.]]\n","\n","  [[140. 108.  87.]\n","   [141. 109.  88.]\n","   [143. 111.  90.]\n","   ...\n","   [134. 101.  86.]\n","   [147. 114.  99.]\n","   [138. 105.  90.]]\n","\n","  [[140. 108.  87.]\n","   [141. 109.  88.]\n","   [143. 111.  90.]\n","   ...\n","   [133. 100.  85.]\n","   [147. 114.  99.]\n","   [138. 105.  90.]]\n","\n","  ...\n","\n","  [[130. 113.  87.]\n","   [126. 109.  83.]\n","   [127. 110.  84.]\n","   ...\n","   [143. 117. 100.]\n","   [140. 114.  97.]\n","   [136. 110.  93.]]\n","\n","  [[130. 114.  88.]\n","   [125. 109.  83.]\n","   [126. 109.  83.]\n","   ...\n","   [143. 117. 100.]\n","   [140. 114.  97.]\n","   [134. 108.  91.]]\n","\n","  [[130. 114.  88.]\n","   [125. 109.  83.]\n","   [126. 109.  83.]\n","   ...\n","   [143. 117. 100.]\n","   [139. 113.  96.]\n","   [134. 108.  91.]]]\n","\n","\n"," [[[170. 130. 156.]\n","   [174. 134. 160.]\n","   [180. 140. 166.]\n","   ...\n","   [172. 125. 145.]\n","   [170. 125. 145.]\n","   [172. 127. 147.]]\n","\n","  [[173. 133. 159.]\n","   [176. 136. 162.]\n","   [179. 139. 165.]\n","   ...\n","   [175. 128. 148.]\n","   [177. 132. 152.]\n","   [181. 136. 156.]]\n","\n","  [[176. 136. 162.]\n","   [177. 137. 163.]\n","   [178. 138. 164.]\n","   ...\n","   [180. 133. 153.]\n","   [185. 140. 160.]\n","   [190. 145. 165.]]\n","\n","  ...\n","\n","  [[162. 120. 140.]\n","   [162. 120. 140.]\n","   [160. 118. 138.]\n","   ...\n","   [170. 121. 140.]\n","   [167. 120. 138.]\n","   [167. 120. 138.]]\n","\n","  [[162. 120. 140.]\n","   [162. 120. 140.]\n","   [159. 117. 137.]\n","   ...\n","   [168. 119. 138.]\n","   [167. 120. 138.]\n","   [171. 124. 142.]]\n","\n","  [[162. 120. 140.]\n","   [161. 119. 139.]\n","   [158. 116. 136.]\n","   ...\n","   [167. 118. 137.]\n","   [167. 120. 138.]\n","   [173. 126. 144.]]]\n","\n","\n"," ...\n","\n","\n"," [[[  0.   0.   0.]\n","   [  0.   0.   0.]\n","   [  0.   0.   0.]\n","   ...\n","   [  0.   0.   0.]\n","   [  0.   0.   0.]\n","   [  0.   0.   0.]]\n","\n","  [[  0.   0.   0.]\n","   [  0.   0.   0.]\n","   [  0.   0.   0.]\n","   ...\n","   [  0.   0.   0.]\n","   [  0.   0.   0.]\n","   [  0.   0.   0.]]\n","\n","  [[  0.   0.   0.]\n","   [  0.   0.   0.]\n","   [  0.   0.   0.]\n","   ...\n","   [  0.   0.   0.]\n","   [  0.   0.   0.]\n","   [  0.   0.   0.]]\n","\n","  ...\n","\n","  [[  0.   0.   0.]\n","   [  0.   0.   0.]\n","   [  0.   0.   0.]\n","   ...\n","   [  1.   1.   1.]\n","   [  1.   1.   1.]\n","   [  1.   1.   1.]]\n","\n","  [[  0.   0.   0.]\n","   [  0.   0.   0.]\n","   [  0.   0.   0.]\n","   ...\n","   [  1.   1.   1.]\n","   [  1.   1.   1.]\n","   [  1.   1.   1.]]\n","\n","  [[  0.   0.   0.]\n","   [  0.   0.   0.]\n","   [  0.   0.   0.]\n","   ...\n","   [  1.   1.   1.]\n","   [  1.   1.   1.]\n","   [  1.   1.   1.]]]\n","\n","\n"," [[[158. 136. 138.]\n","   [152. 131. 128.]\n","   [151. 126. 121.]\n","   ...\n","   [145. 133. 121.]\n","   [135. 122. 114.]\n","   [131. 121. 112.]]\n","\n","  [[158. 136. 138.]\n","   [153. 129. 127.]\n","   [150. 125. 118.]\n","   ...\n","   [154. 140. 129.]\n","   [134. 121. 113.]\n","   [120. 110. 101.]]\n","\n","  [[159. 135. 135.]\n","   [152. 128. 126.]\n","   [148. 123. 116.]\n","   ...\n","   [161. 147. 136.]\n","   [140. 127. 119.]\n","   [121. 108. 100.]]\n","\n","  ...\n","\n","  [[163. 148. 145.]\n","   [164. 146. 144.]\n","   [164. 140. 138.]\n","   ...\n","   [145. 127. 115.]\n","   [140. 122. 110.]\n","   [139. 121. 109.]]\n","\n","  [[162. 146. 146.]\n","   [164. 146. 144.]\n","   [165. 141. 139.]\n","   ...\n","   [140. 122. 110.]\n","   [138. 120. 108.]\n","   [141. 123. 111.]]\n","\n","  [[161. 145. 145.]\n","   [163. 145. 143.]\n","   [166. 142. 142.]\n","   ...\n","   [137. 119. 107.]\n","   [136. 118. 106.]\n","   [143. 125. 113.]]]\n","\n","\n"," [[[ 46.  51.  57.]\n","   [ 51.  54.  59.]\n","   [ 77.  72.  76.]\n","   ...\n","   [117. 114. 109.]\n","   [121. 121. 119.]\n","   [121. 126. 122.]]\n","\n","  [[ 48.  53.  59.]\n","   [ 59.  60.  65.]\n","   [ 78.  73.  77.]\n","   ...\n","   [129. 124. 120.]\n","   [133. 134. 129.]\n","   [124. 129. 125.]]\n","\n","  [[ 53.  56.  61.]\n","   [ 61.  62.  66.]\n","   [ 70.  66.  67.]\n","   ...\n","   [130. 125. 121.]\n","   [134. 133. 129.]\n","   [121. 123. 118.]]\n","\n","  ...\n","\n","  [[193. 194. 189.]\n","   [192. 193. 188.]\n","   [188. 187. 182.]\n","   ...\n","   [ 57.  53.  54.]\n","   [ 77.  66.  72.]\n","   [120. 107. 114.]]\n","\n","  [[191. 193. 188.]\n","   [192. 193. 188.]\n","   [188. 187. 183.]\n","   ...\n","   [ 63.  59.  60.]\n","   [ 96.  85.  91.]\n","   [105.  92. 101.]]\n","\n","  [[191. 193. 188.]\n","   [189. 191. 186.]\n","   [185. 184. 180.]\n","   ...\n","   [ 78.  76.  77.]\n","   [121. 110. 116.]\n","   [100.  87.  96.]]]]\n"]}],"source":["# Making sure it's a 2D array\n","image_matrix = np.stack(df['image_array'].values)\n","print(image_matrix)"]},{"cell_type":"code","execution_count":null,"id":"0b07fdf8","metadata":{},"outputs":[],"source":["# It's a three dimensions array so we have to flatten it \n","image_matrix = np.array([img.flatten() for img in df['image_array']])\n","\n","# Scale the data\n","scaler = StandardScaler()\n","image_matrix_scaled = scaler.fit_transform(image_matrix)"]},{"cell_type":"code","execution_count":null,"id":"319d7906","metadata":{"execution":{"iopub.execute_input":"2024-05-10T18:09:49.276916Z","iopub.status.busy":"2024-05-10T18:09:49.276554Z"},"papermill":{"duration":0.020456,"end_time":"2024-05-09T20:23:09.245954","exception":false,"start_time":"2024-05-09T20:23:09.225498","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import time\n","\n","# Start timing the overall process\n","start_time_overall = time.time()\n","\n","# Principal Component Analysis\n","pca_ratio=PCA()\n","pca_ratio.fit(image_matrix_scaled) # fit the PCA so it can learn\n","\n","# Using cumulative variance\n","cumulative_variance_ratio=np.cumsum(pca_ratio.explained_variance_ratio_)\n","variance=0.95 # set to 95% to keep a sufficiently large portion of the variance\n","n_components= np.argmax(cumulative_variance_ratio >= variance) +1 # find the number of components needed \n","\n","print(f\"Number of principal components: {n_components}\")\n","\n","# Calculate and print the overall running time\n","overall_time = time.time() - start_time_overall\n","print(f\"Total running time: {overall_time:.2f} seconds.\")\n","\n","# There is another way to obtain the number of components which is setting the threshold \n","# pca_threshold = PCA(n_components=0.95)\n","# pca_threshold.fit(image_matrix_scaled) - fit the pca model to the data to learn patterns\n","# print(f\"Number of principal components: {pca_threshold.n_components_}\")"]},{"attachments":{},"cell_type":"markdown","id":"71316f40","metadata":{},"source":["Number of principal components: 72"]},{"cell_type":"code","execution_count":null,"id":"43f7ec86","metadata":{},"outputs":[],"source":["\n","# Screen plot eigenvalues - number of principal components\n","plt.figure(figsize=(10, 6))\n","sns.lineplot(x=np.arange(1, len(cumulative_variance_ratio) + 1), y=cumulative_variance_ratio, marker='o', color='#FF69B4')\n","plt.title('Scree Plot')\n","plt.xlabel('Number of Components')\n","plt.ylabel('Cumulative Explained Variance Ratio')\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"e7db175a","metadata":{"papermill":{"duration":0.020219,"end_time":"2024-05-09T20:23:09.286611","exception":false,"start_time":"2024-05-09T20:23:09.266392","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Transform the original data using retained principal components \n","# Start from inputting in PCA the number of components found necessary for 95% variance\n","pca_opt=PCA(n_components=72)\n","pca_opt.fit(image_matrix_scaled)\n","\n","df_matrix_reduced= pca_opt.transform(image_matrix_scaled) # transform the flatten original data to reduced dimensionality"]},{"attachments":{},"cell_type":"markdown","id":"adb332d2","metadata":{},"source":["# SVM"]},{"cell_type":"code","execution_count":null,"id":"405a9932","metadata":{},"outputs":[],"source":["from sklearn.svm import SVC\n","from sklearn.metrics import classification_report, accuracy_score\n","from sklearn.model_selection import GridSearchCV\n","import time\n","\n","# Start timing the overall process\n","start_time_overall = time.time()\n","\n","# Split the Data in test and train\n","train_indices = df[df['subset'] == 'train'].index\n","test_indices = df[df['subset'] == 'test'].index\n","\n","X_train = df_matrix_reduced[train_indices]\n","X_test = df_matrix_reduced[test_indices]\n","y_train = df.loc[train_indices, 'category']\n","y_test = df.loc[test_indices, 'category']\n","\n","# Definition of the parameter grid for GridSearchCV\n","param_grid = {\n","    'C': [0.1, 1, 10, 100],\n","    'gamma': [0.0001, 0.001, 0.1, 1],\n","    'kernel': ['rbf', 'poly']\n","}\n","\n","# Creation of an SVC\n","svc = SVC(probability=True)\n","\n","# Creating the model using GridSearchCV with the parameter grid\n","model = GridSearchCV(svc, param_grid, cv=3, n_jobs=-1)\n","\n","# Training the model using training data\n","model.fit(X_train, y_train)\n","\n","# Print the best parameters\n","print(\"Best parameters found:\", model.best_params_)\n","\n","# Testing the model using test data\n","y_pred = model.predict(X_test)\n","\n","# Printing the classification report\n","print(classification_report(y_test, y_pred))\n","\n","# Calculate and print the overall running time\n","overall_time = time.time() - start_time_overall\n","print(f\"Total running time: {overall_time:.2f} seconds.\")"]},{"attachments":{},"cell_type":"markdown","id":"78259c1a","metadata":{},"source":["SVM with PCA - sample of dataset"]},{"cell_type":"code","execution_count":null,"id":"de95630d","metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","import time\n","\n","# Start timing the overall process\n","start_time_overall = time.time()\n","\n","# Indices for training and testing data as defined in the 'subset' column\n","train_indices = df[df['subset'] == 'train'].index\n","test_indices = df[df['subset'] == 'test'].index\n","\n","# Randomly select 20% of the data from both training and testing subsets\n","train_indices_sample = train_test_split(train_indices, train_size=0.2, random_state=42)[0]\n","test_indices_sample = train_test_split(test_indices, test_size=0.2, random_state=42)[1]\n","\n","# Assign features and targets based on the selected indices\n","X_train = df_matrix_reduced[train_indices_sample]\n","X_test = df_matrix_reduced[test_indices_sample]\n","y_train = df.loc[train_indices_sample, 'category']\n","y_test = df.loc[test_indices_sample, 'category']\n","\n","# Import and configure the SVM model with GridSearchCV\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import GridSearchCV\n","\n","param_grid = {\n","    'C': [0.1, 1, 10, 100],\n","    'gamma': [0.0001, 0.001, 0.1, 1],\n","    'kernel': ['rbf', 'poly']\n","}\n","\n","svc = SVC(probability=True)\n","model = GridSearchCV(svc, param_grid, cv=5, n_jobs=-1)\n","model.fit(X_train, y_train)\n","\n","# Print the best parameters\n","print(\"Best parameters found:\", model.best_params_)\n","\n","# Testing the model using test data\n","y_pred = model.predict(X_test)\n","\n","# Printing the classification report\n","print(classification_report(y_test, y_pred))\n","\n","# Calculate and print the overall running time\n","overall_time = time.time() - start_time_overall\n","print(f\"Total running time: {overall_time:.2f} seconds.\")"]},{"attachments":{},"cell_type":"markdown","id":"309af1a2","metadata":{},"source":["## SVM without PCA"]},{"cell_type":"code","execution_count":null,"id":"87d3424a","metadata":{},"outputs":[],"source":["import time\n","\n","# Start timing the overall process\n","start_time_overall = time.time()\n","\n","# SVM without PCA\n","X_train = image_matrix_scaled[df['subset'] == 'train']\n","y_train = df[df['subset'] == 'train']['category']\n","X_test = image_matrix_scaled[df['subset'] == 'test']\n","y_test = df[df['subset'] == 'test']['category']\n","\n","# Definition of the parameter grid for GridSearchCV\n","param_grid = {\n","    'C': [0.1, 1, 10, 100],\n","    'gamma': [0.0001, 0.001, 0.1, 1],\n","    'kernel': ['rbf', 'poly']\n","}\n","\n","# Creation of an SVC\n","svc = SVC(probability=True)\n","\n","# Creating the model using GridSearchCV with the parameter grid\n","model = GridSearchCV(svc, param_grid, cv=3, n_jobs=-1)\n","\n","# Training the model using training data\n","model.fit(X_train, y_train)\n","\n","# Print the best parameters\n","print(\"Best parameters found:\", model.best_params_)\n","\n","# Testing the model using test data\n","y_pred = model.predict(X_test)\n","\n","# Printing the classification report\n","print(classification_report(y_test, y_pred))\n","\n","# Calculate and print the overall running time\n","overall_time = time.time() - start_time_overall\n","print(f\"Total running time: {overall_time:.2f} seconds.\")"]},{"attachments":{},"cell_type":"markdown","id":"2023d7ca","metadata":{},"source":["SVM without PCA - sample of dataset"]},{"cell_type":"code","execution_count":null,"id":"e9d5402a","metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","import time\n","\n","# Start timing the overall process\n","start_time_overall = time.time()\n","\n","# Indices for training and testing data as defined in the 'subset' column\n","train_indices = df[df['subset'] == 'train'].index\n","test_indices = df[df['subset'] == 'test'].index\n","\n","# Randomly select 20% of the data from both training and testing subsets\n","train_indices_sample = train_test_split(train_indices, train_size=0.2, random_state=42)[0]\n","test_indices_sample = train_test_split(test_indices, test_size=0.2, random_state=42)[1]\n","\n","# Assign features and targets based on the selected indices\n","X_train = image_matrix_scaled[train_indices_sample]\n","X_test = image_matrix_scaled[test_indices_sample]\n","y_train = df.loc[train_indices_sample, 'category']\n","y_test = df.loc[test_indices_sample, 'category']\n","\n","# Import and configure the SVM model with GridSearchCV\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import GridSearchCV\n","\n","param_grid = {\n","    'C': [0.1, 1, 10, 100],\n","    'gamma': [0.0001, 0.001, 0.1, 1],\n","    'kernel': ['rbf', 'poly']\n","}\n","\n","svc = SVC(probability=True)\n","model = GridSearchCV(svc, param_grid, cv=3, n_jobs=-1)\n","model.fit(X_train, y_train)\n","\n","# Divide test data into 4 batches for classification\n","batch_size = len(X_test) // 4  # Calculate the batch size based on the total number of samples in the test set\n","\n","for i in range(4):\n","    start_index = i * batch_size\n","    end_index = start_index + batch_size if i < 3 else len(X_test)  # Ensure the last batch includes all remaining data\n","\n","    X_batch = X_test[start_index:end_index]\n","    y_batch = y_test[start_index:end_index]\n","    \n","    # Predict model on the batch\n","    y_pred_batch = model.predict(X_batch)\n","    \n","    # Print the classification report for the current batch\n","    print(f\"Classification Report for Batch {i+1}\")\n","    print(classification_report(y_batch, y_pred_batch))\n","    print(\"\\n\" + \"-\"*80 + \"\\n\")\n","\n","# Calculate and print the overall running time\n","overall_time = time.time() - start_time_overall\n","print(f\"Total running time: {overall_time:.2f} seconds.\")"]},{"attachments":{},"cell_type":"markdown","id":"69df070b","metadata":{},"source":["# SVM without PCA with SGDClassifier"]},{"cell_type":"code","execution_count":null,"id":"85d67a17","metadata":{},"outputs":[],"source":["from sklearn.linear_model import SGDClassifier\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import GridSearchCV\n","import time\n","\n","# Start timing the overall process\n","start_time_overall = time.time()\n","\n","# SVM without PCA\n","X_train = image_matrix_scaled[df['subset'] == 'train']\n","y_train = df[df['subset'] == 'train']['category']\n","X_test = image_matrix_scaled[df['subset'] == 'test']\n","y_test = df[df['subset'] == 'test']['category']\n","\n","# Define parameter grid for SGDClassifier\n","param_grid_sgd = {\n","    'alpha': [0.0001, 0.001, 0.01, 0.1],  # Regularization parameter\n","    'penalty': ['l2', 'l1', 'elasticnet'],\n","    'loss': ['hinge']  # Hinge loss corresponds to a linear SVM\n","}\n","\n","# Create SGDClassifier\n","sgd = SGDClassifier(max_iter=1000, tol=1e-3)\n","\n","# Create GridSearchCV model\n","grid_search_sgd = GridSearchCV(sgd, param_grid_sgd, cv=3, n_jobs=-1)\n","\n","# Train model using training data\n","grid_search_sgd.fit(X_train, y_train)\n","\n","# Print the best parameters\n","print(\"Best parameters found:\", model.best_params_)\n","\n","# Test model using test data\n","y_pred_sgd = grid_search_sgd.predict(X_test)\n","\n","# Print classification report\n","print(classification_report(y_test,y_pred_sgd))\n","\n","# Calculate and print the overall running time\n","overall_time = time.time() - start_time_overall\n","print(f\"Total running time: {overall_time:.2f} seconds.\")"]},{"attachments":{},"cell_type":"markdown","id":"49c787cd","metadata":{},"source":["CNN"]},{"cell_type":"code","execution_count":null,"id":"3f96be1f","metadata":{},"outputs":[],"source":["#IMPORTING LIBRARIES\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from keras import layers"]},{"attachments":{},"cell_type":"markdown","id":"0e9160ba","metadata":{},"source":["LOAD AND NORMALISE DATA"]},{"cell_type":"code","execution_count":null,"id":"c7880173","metadata":{},"outputs":[],"source":["# To make this notebook’s output stable across runs\n","np.random.seed(50)\n","tf.random.set_seed(50)\n","\n","\n","# Load the Dataset - we already run this above, but we run it again just to make sure this cell runs without running all the above cells\n","X_train = image_matrix_scaled[df['subset'] == 'train']\n","y_train = df[df['subset'] == 'train']['category']\n","X_test = image_matrix_scaled[df['subset'] == 'test']\n","y_test = df[df['subset'] == 'test']['category']\n","\n","\n","# Normalize pixel values to be between 0 and 1\n","X_train = X_train.astype(np.float32) / 255\n","X_test = X_test.astype(np.float32) / 255"]},{"attachments":{},"cell_type":"markdown","id":"68f58ddd","metadata":{},"source":["### THE FOLLOWING CELL IS AN ATTEMPT TO VISUALISE DATA. IT IS NOT PART OF THE CNN MODEL. \n","### DO NOT PANIC IF IT DOES NOT RUN."]},{"cell_type":"code","execution_count":null,"id":"c6b197a6","metadata":{},"outputs":[],"source":["#we already run this above, but we run it again just to make sure this cell runs without running all the above cells\n","categories = {'Benign': 0, 'Malignant': 1, 'Undetected': 2}\n","\n","# visualising images with numeric tags and names  \n","def display_images_with_labels(images, labels, categories, num_images=10, tagnum = None):\n","    plt.figure(figsize=(10,10))\n","    # select only images with specified tag number\n","    if tagnum >=0 and tagnum<3: \n","        indices = np.where(np.array([str(label) for label in labels]) == str(tagnum))[0][:num_images]\n","    # otherwise select randomly\n","    else: \n","        indices = np.random.choice(range(len(images)), num_images, replace=False)\n","    for i, index in enumerate(indices):\n","        plt.subplot(5, 5, i + 1)\n","        plt.xticks([])\n","        plt.yticks([])\n","        plt.grid(False)\n","        plt.imshow(images[index], cmap=plt.cm.binary)\n","         # if there is a list of class names, show both tag number and class name\n","        if categories:\n","            label_with_name = f\"{labels[index]} ({categories[labels[index]]})\"\n","            plt.xlabel(label_with_name)\n","        # othwerwise visualise only tag number\n","        else:\n","            plt.xlabel(labels[index])\n","    plt.show()\n","\n","display_images_with_labels(X_train, y_train, categories, num_images=25, category = 0)"]},{"attachments":{},"cell_type":"markdown","id":"63f900bf","metadata":{},"source":["CREATING THE MODEL"]},{"cell_type":"code","execution_count":null,"id":"25d5eb0d","metadata":{},"outputs":[],"source":["## Creating the models\n","# Lower Model\n","lower_model = keras.Sequential()\n","lower_model.add(keras.Input(shape=(28, 28, 1)))  # 28x28 B&W\n","\n","lower_model.add(layers.Conv2D(32, 3, activation=\"relu\", padding='same', kernel_initializer='he_normal'))\n","lower_model.add(layers.MaxPooling2D(2))\n","\n","lower_model.add(layers.Conv2D(64, 3, activation=\"relu\", padding='same', kernel_initializer='he_normal'))\n","lower_model.add(layers.MaxPooling2D(2))\n","\n","# Upper Model\n","upper_model = keras.Sequential()\n","upper_model.add(layers.Flatten()) \n","\n","upper_model.add(layers.Dense(128, activation='relu', kernel_initializer='he_normal'))\n","upper_model.add(layers.Dense(10, activation='softmax'))\n","\n","# Prepare the training dataset.\n","batch_size = 32\n","train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(1024).batch(batch_size)\n","val_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size)\n","\n","# Optimizer for the lower layers\n","lower_optimizer = keras.optimizers.SGD(learning_rate=1e-4)\n","# Optimizer for the upper layers\n","upper_optimizer = keras.optimizers.Nadam(learning_rate=1e-3)\n","# Instantiate a loss function.\n","loss_fn = keras.losses.SparseCategoricalCrossentropy()\n","\n","# Prepare the testing dataset.\n","val_dataset = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n","val_dataset = val_dataset.batch(batch_size)"]},{"attachments":{},"cell_type":"markdown","id":"bd0f108e","metadata":{},"source":["INITIALISING METRICS AND RUNNING CNN MODEL"]},{"cell_type":"code","execution_count":null,"id":"9716cf9e","metadata":{},"outputs":[],"source":["# Initialize metrics at the start of each epoch\n","loss_avg = keras.metrics.Mean()\n","accuracy = keras.metrics.SparseCategoricalAccuracy()\n","val_loss_avg = keras.metrics.Mean()\n","val_accuracy = keras.metrics.SparseCategoricalAccuracy()\n","\n","# Training Loop\n","epochs = 5\n","for epoch in range(epochs):\n","    print(f\"\\nStart of epoch {epoch}\")\n","\n","    # Iterate over the batches of the training dataset\n","    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n","        # Calculating the intermediate activations of the lower and upper model \n","        with tf.GradientTape(persistent=True) as tape:\n","            lower_logits = lower_model(x_batch_train, training=True)\n","            logits = upper_model(lower_logits, training=True)\n","        # Calcutating the loss\n","            loss_value = loss_fn(y_batch_train, logits)\n","\n","        # Gradient computation for both the models\n","        lower_grads = tape.gradient(loss_value, lower_model.trainable_weights)\n","        upper_grads = tape.gradient(loss_value, upper_model.trainable_weights)\n","        \n","        # Apply optimizers\n","        lower_optimizer.apply_gradients(zip(lower_grads, lower_model.trainable_weights))\n","        upper_optimizer.apply_gradients(zip(upper_grads, upper_model.trainable_weights))\n","\n","        # Update training metrics\n","        loss_avg.update_state(loss_value)\n","        accuracy.update_state(y_batch_train, logits)\n","\n","    # Print the mean training loss and accuracy over the epoch\n","    train_loss = loss_avg.result()\n","    train_accuracy = accuracy.result()\n","    print(f\"Training loss over epoch: {float(train_loss):.4f}\")\n","    print(f\"Training accuracy over epoch: {float(train_accuracy):.4f}\")\n","\n","\n","    # Perform validation at the end of the epoch\n","    for x_batch_val, y_batch_val in val_dataset:\n","        lower_val_logits = lower_model(x_batch_val, training=False)\n","        val_logits = upper_model(lower_val_logits, training=False)\n","        val_loss_value = loss_fn(y_batch_val, val_logits)\n","    \n","        val_loss_avg.update_state(val_loss_value)\n","        val_accuracy.update_state(y_batch_val, val_logits)\n","    \n","    # Compute the mean validation loss and accuracy for the epoch\n","    val_loss = val_loss_avg.result()\n","    val_acc = val_accuracy.result()\n","    print(f\"Validation loss: {float(val_loss):.4f}\")\n","    print(f\"Validation accuracy: {float(val_acc):.4f}\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30698,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"papermill":{"default_parameters":{},"duration":69.191232,"end_time":"2024-05-09T20:23:11.684837","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-05-09T20:22:02.493605","version":"2.5.0"}},"nbformat":4,"nbformat_minor":5}
